{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e71c31e8a0a948b98494da66e7a49bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c502ae470338410c8bde35c876cd462e",
              "IPY_MODEL_4bc3201575b741ca8b9c8093470cf191",
              "IPY_MODEL_00fadb095582496ea3b9e55e11764c2b"
            ],
            "layout": "IPY_MODEL_5d48a53c271549d996263bb34530bf5b"
          }
        },
        "c502ae470338410c8bde35c876cd462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a22103ab3c4954ab4e90b18a0e7b06",
            "placeholder": "​",
            "style": "IPY_MODEL_36465222fb5841b7a55a8a8ef0b75899",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "4bc3201575b741ca8b9c8093470cf191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5add6bdf750e440bb132a6c56497e999",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e64e4abb7c1f48989db2c7b238d1237d",
            "value": 760
          }
        },
        "00fadb095582496ea3b9e55e11764c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2666643602f94a91a906d9c598e81036",
            "placeholder": "​",
            "style": "IPY_MODEL_2ecd9c2756d144fb963db88d6504641c",
            "value": " 760/760 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "5d48a53c271549d996263bb34530bf5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a22103ab3c4954ab4e90b18a0e7b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36465222fb5841b7a55a8a8ef0b75899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5add6bdf750e440bb132a6c56497e999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64e4abb7c1f48989db2c7b238d1237d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2666643602f94a91a906d9c598e81036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ecd9c2756d144fb963db88d6504641c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162bb3e65ee942f88362616f9ca11393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c60248b18df748c1bb3f13406a5a7d7b",
              "IPY_MODEL_46d42ba5d9cf4dc29e19cdebd223b643",
              "IPY_MODEL_e9201bcd368b4c38a8587981721971bb"
            ],
            "layout": "IPY_MODEL_ea50715432b4456eac00753bff3ce8e2"
          }
        },
        "c60248b18df748c1bb3f13406a5a7d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1dd8b3a016144e397846a9263d646c0",
            "placeholder": "​",
            "style": "IPY_MODEL_410350f1552b4aabb53c9c65ed961570",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "46d42ba5d9cf4dc29e19cdebd223b643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ea4042a546b409793020068b01932b8",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94ce6f0fe2a7424dae0a833ad9fe1743",
            "value": 898823
          }
        },
        "e9201bcd368b4c38a8587981721971bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfb7833ff7c4ba4a1d3dc6d5a3c2e13",
            "placeholder": "​",
            "style": "IPY_MODEL_40d58b9e5b2c4bfeb9a913befbc0b26e",
            "value": " 899k/899k [00:00&lt;00:00, 3.63MB/s]"
          }
        },
        "ea50715432b4456eac00753bff3ce8e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1dd8b3a016144e397846a9263d646c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410350f1552b4aabb53c9c65ed961570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ea4042a546b409793020068b01932b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ce6f0fe2a7424dae0a833ad9fe1743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acfb7833ff7c4ba4a1d3dc6d5a3c2e13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d58b9e5b2c4bfeb9a913befbc0b26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fc9de4c2f64e94a0f7864e2d54e368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66838f08b9b4442ab25a10b31b068984",
              "IPY_MODEL_2b1f534aa7994a56b2d3143cebb60670",
              "IPY_MODEL_a9a646e5cb7a4e58ba8570427202bcda"
            ],
            "layout": "IPY_MODEL_56f82cfa843b4a86ab7a83405de7e109"
          }
        },
        "66838f08b9b4442ab25a10b31b068984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7e040c0f344024907a0706ae6c4c46",
            "placeholder": "​",
            "style": "IPY_MODEL_a2f5c37fea9c40b09387a02741b287f9",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "2b1f534aa7994a56b2d3143cebb60670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3143cf223da4890988333467fb73479",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9375581fee2c481fb90ddbf30de10070",
            "value": 456318
          }
        },
        "a9a646e5cb7a4e58ba8570427202bcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e25f0e61fbb4e37b0fd2edb57785365",
            "placeholder": "​",
            "style": "IPY_MODEL_0182a6e3a2f848dfacf312f8128a7a39",
            "value": " 456k/456k [00:00&lt;00:00, 2.76MB/s]"
          }
        },
        "56f82cfa843b4a86ab7a83405de7e109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7e040c0f344024907a0706ae6c4c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f5c37fea9c40b09387a02741b287f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3143cf223da4890988333467fb73479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9375581fee2c481fb90ddbf30de10070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e25f0e61fbb4e37b0fd2edb57785365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0182a6e3a2f848dfacf312f8128a7a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9427d2a06d394a44a78ea53726718bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d96baccfc10d476ab1696026481ed192",
              "IPY_MODEL_be17467ff0ec42b9a836e1c03964517a",
              "IPY_MODEL_dd26b4eb82574af7b921bb74234e2249"
            ],
            "layout": "IPY_MODEL_9f1f2d88a267496ab95ddc1876259a50"
          }
        },
        "d96baccfc10d476ab1696026481ed192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d893e5550f547f387263c8a57765246",
            "placeholder": "​",
            "style": "IPY_MODEL_8796157bf6c145dab85f37d5b844e8d2",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "be17467ff0ec42b9a836e1c03964517a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3af5ec211644faaaddacd2213a5e2f4",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_569d38009b9242a7a61585a39b162df8",
            "value": 1355863
          }
        },
        "dd26b4eb82574af7b921bb74234e2249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1687f996d5b49e7baaea72ad2f591a4",
            "placeholder": "​",
            "style": "IPY_MODEL_fd8d0d9af49f41e5b71bb5ff0cffbd4d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 15.5MB/s]"
          }
        },
        "9f1f2d88a267496ab95ddc1876259a50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d893e5550f547f387263c8a57765246": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8796157bf6c145dab85f37d5b844e8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3af5ec211644faaaddacd2213a5e2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569d38009b9242a7a61585a39b162df8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1687f996d5b49e7baaea72ad2f591a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8d0d9af49f41e5b71bb5ff0cffbd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df746c39966940d4845254fa2839a48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90ad22e5d7934e53abd67767b380dd36",
              "IPY_MODEL_580a8b3275cc4303a43aecaa9ade25cf",
              "IPY_MODEL_b2f1581955894d029a34fe3df3c6df29"
            ],
            "layout": "IPY_MODEL_440aea8a94b540e7a55c38f8314420ea"
          }
        },
        "90ad22e5d7934e53abd67767b380dd36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33336db927c4127a585a986e225123e",
            "placeholder": "​",
            "style": "IPY_MODEL_8a49957e719b4bd9b725edf53b47419b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "580a8b3275cc4303a43aecaa9ade25cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f238156864ca4ddc9783de9b158c9a98",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd466e40703d48f6bcb48926eb13f112",
            "value": 481
          }
        },
        "b2f1581955894d029a34fe3df3c6df29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312722434a2a4063876254c0a60c0c58",
            "placeholder": "​",
            "style": "IPY_MODEL_4a59ecddb8b745adb679f4415d2dc821",
            "value": " 481/481 [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "440aea8a94b540e7a55c38f8314420ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33336db927c4127a585a986e225123e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a49957e719b4bd9b725edf53b47419b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f238156864ca4ddc9783de9b158c9a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd466e40703d48f6bcb48926eb13f112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "312722434a2a4063876254c0a60c0c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a59ecddb8b745adb679f4415d2dc821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "#!pip install iterative-stratification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0jU4QHwuk-D",
        "outputId": "116e2d1e-0c00-4c03-f317-2ac88aae2cdb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iterative-stratification) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iterative-stratification) (3.2.0)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sronger/PSG_Predicting_Algorithm_Tags_and_Difficulty.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YByoWsRgz9_3",
        "outputId": "f6a57ed6-db4a-47ed-b176-2aeb0a342947"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PSG_Predicting_Algorithm_Tags_and_Difficulty'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 19 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (19/19), 4.76 MiB | 3.59 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PSG_Predicting_Algorithm_Tags_and_Difficulty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMn6OtZfrE0i",
        "outputId": "8a658af2-dbd9-40a5-f23a-1aa244ff7417"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PSG_Predicting_Algorithm_Tags_and_Difficulty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, RobertaTokenizer\n",
        "#from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "import shutil\n",
        "from itertools import chain\n",
        "\n",
        "import ast"
      ],
      "metadata": {
        "id": "zfUMdBO0uOhf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/AMT10/AMT10_train.csv', index_col=0, encoding='utf8')\n",
        "valid_df = pd.read_csv('./data/AMT10/AMT10_validation.csv', index_col=0, encoding='utf8')\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wrELTfIPxW27",
        "outputId": "6f43461d-6c67-4873-a92d-30d4c0920041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              description  \\\n",
              "1845/E  $$$ n $$$ box place a line box number $$$ 1 $$...   \n",
              "1845/B  bob carol hang alice whole day 's time go home...   \n",
              "1845/A  give integer $$$ n $$$ want obtain unlimited s...   \n",
              "1841/B  array $$$ [ a_1 a_2 \\dots a_k ] $$$ call beaut...   \n",
              "1839/A  give two integers $$$ n $$$ $$$ k $$$ array $$...   \n",
              "\n",
              "                                                     tags  rating  \n",
              "1845/E                   ['dp', 'implementation', 'math']  2500.0  \n",
              "1845/B             ['geometry', 'implementation', 'math']   900.0  \n",
              "1845/A  ['constructive algorithms', 'implementation', ...   800.0  \n",
              "1841/B                                 ['implementation']  1000.0  \n",
              "1839/A               ['greedy', 'implementation', 'math']   800.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fd68ce6-7c03-4529-92fc-52a6386b3c06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1845/E</th>\n",
              "      <td>$$$ n $$$ box place a line box number $$$ 1 $$...</td>\n",
              "      <td>['dp', 'implementation', 'math']</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845/B</th>\n",
              "      <td>bob carol hang alice whole day 's time go home...</td>\n",
              "      <td>['geometry', 'implementation', 'math']</td>\n",
              "      <td>900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845/A</th>\n",
              "      <td>give integer $$$ n $$$ want obtain unlimited s...</td>\n",
              "      <td>['constructive algorithms', 'implementation', ...</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841/B</th>\n",
              "      <td>array $$$ [ a_1 a_2 \\dots a_k ] $$$ call beaut...</td>\n",
              "      <td>['implementation']</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839/A</th>\n",
              "      <td>give two integers $$$ n $$$ $$$ k $$$ array $$...</td>\n",
              "      <td>['greedy', 'implementation', 'math']</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd68ce6-7c03-4529-92fc-52a6386b3c06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fd68ce6-7c03-4529-92fc-52a6386b3c06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fd68ce6-7c03-4529-92fc-52a6386b3c06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c24b9c1-d919-4e87-b2dc-132ec5a95f3c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c24b9c1-d919-4e87-b2dc-132ec5a95f3c')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c24b9c1-d919-4e87-b2dc-132ec5a95f3c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AMT10 = [\n",
        "    'implementation',\n",
        "    'dp',\n",
        "    'math',\n",
        "    'greedy',\n",
        "    'data structures',\n",
        "    'brute force',\n",
        "    'geometry',\n",
        "    'constructive algorithms',\n",
        "    'dfs and similar',\n",
        "    'strings'\n",
        "]"
      ],
      "metadata": {
        "id": "ZqXxXdkSxcmp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = AutoConfig.from_pretrained(\"google/bigbird-roberta-base\", max_position_embeddings=1024)\n",
        "model_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652,
          "referenced_widgets": [
            "e71c31e8a0a948b98494da66e7a49bf8",
            "c502ae470338410c8bde35c876cd462e",
            "4bc3201575b741ca8b9c8093470cf191",
            "00fadb095582496ea3b9e55e11764c2b",
            "5d48a53c271549d996263bb34530bf5b",
            "a7a22103ab3c4954ab4e90b18a0e7b06",
            "36465222fb5841b7a55a8a8ef0b75899",
            "5add6bdf750e440bb132a6c56497e999",
            "e64e4abb7c1f48989db2c7b238d1237d",
            "2666643602f94a91a906d9c598e81036",
            "2ecd9c2756d144fb963db88d6504641c"
          ]
        },
        "id": "Wvy4DGDBudmz",
        "outputId": "46ad4c7a-c7b8-4328-e421-824e54f508de"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e71c31e8a0a948b98494da66e7a49bf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BigBirdConfig {\n",
              "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"BigBirdForPreTraining\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"attention_type\": \"block_sparse\",\n",
              "  \"block_size\": 64,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu_new\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 1024,\n",
              "  \"model_type\": \"big_bird\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"num_random_blocks\": 3,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"rescale_embeddings\": false,\n",
              "  \"sep_token_id\": 66,\n",
              "  \"transformers_version\": \"4.34.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_bias\": true,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50358\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "URjIRSjwc8na",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "162bb3e65ee942f88362616f9ca11393",
            "c60248b18df748c1bb3f13406a5a7d7b",
            "46d42ba5d9cf4dc29e19cdebd223b643",
            "e9201bcd368b4c38a8587981721971bb",
            "ea50715432b4456eac00753bff3ce8e2",
            "e1dd8b3a016144e397846a9263d646c0",
            "410350f1552b4aabb53c9c65ed961570",
            "1ea4042a546b409793020068b01932b8",
            "94ce6f0fe2a7424dae0a833ad9fe1743",
            "acfb7833ff7c4ba4a1d3dc6d5a3c2e13",
            "40d58b9e5b2c4bfeb9a913befbc0b26e",
            "25fc9de4c2f64e94a0f7864e2d54e368",
            "66838f08b9b4442ab25a10b31b068984",
            "2b1f534aa7994a56b2d3143cebb60670",
            "a9a646e5cb7a4e58ba8570427202bcda",
            "56f82cfa843b4a86ab7a83405de7e109",
            "7d7e040c0f344024907a0706ae6c4c46",
            "a2f5c37fea9c40b09387a02741b287f9",
            "b3143cf223da4890988333467fb73479",
            "9375581fee2c481fb90ddbf30de10070",
            "7e25f0e61fbb4e37b0fd2edb57785365",
            "0182a6e3a2f848dfacf312f8128a7a39",
            "9427d2a06d394a44a78ea53726718bf4",
            "d96baccfc10d476ab1696026481ed192",
            "be17467ff0ec42b9a836e1c03964517a",
            "dd26b4eb82574af7b921bb74234e2249",
            "9f1f2d88a267496ab95ddc1876259a50",
            "9d893e5550f547f387263c8a57765246",
            "8796157bf6c145dab85f37d5b844e8d2",
            "f3af5ec211644faaaddacd2213a5e2f4",
            "569d38009b9242a7a61585a39b162df8",
            "e1687f996d5b49e7baaea72ad2f591a4",
            "fd8d0d9af49f41e5b71bb5ff0cffbd4d",
            "df746c39966940d4845254fa2839a48c",
            "90ad22e5d7934e53abd67767b380dd36",
            "580a8b3275cc4303a43aecaa9ade25cf",
            "b2f1581955894d029a34fe3df3c6df29",
            "440aea8a94b540e7a55c38f8314420ea",
            "f33336db927c4127a585a986e225123e",
            "8a49957e719b4bd9b725edf53b47419b",
            "f238156864ca4ddc9783de9b158c9a98",
            "dd466e40703d48f6bcb48926eb13f112",
            "312722434a2a4063876254c0a60c0c58",
            "4a59ecddb8b745adb679f4415d2dc821"
          ]
        },
        "outputId": "1eab02d0-9858-4322-f5ba-821305ca889a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "162bb3e65ee942f88362616f9ca11393"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25fc9de4c2f64e94a0f7864e2d54e368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9427d2a06d394a44a78ea53726718bf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df746c39966940d4845254fa2839a48c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    'seed' : 42,\n",
        "    'tags' : AMT10,\n",
        "    'batchSize' : 4,\n",
        "    'lr' : 5e-6,\n",
        "    'trainMaxLength' : 1024,\n",
        "    'testMaxLength' : 1024,\n",
        "    'numEpochs' : 200,\n",
        "    'model' : AutoModel.from_config(model_config),\n",
        "    'tokenizer' : RobertaTokenizer.from_pretrained('roberta-base'),\n",
        "    'gradient_accumulation_steps' : 4,\n",
        "    'max_grad_norm' : 1.0,\n",
        "    'lambda' : 10,\n",
        "    'save' : True,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(config['seed'])"
      ],
      "metadata": {
        "id": "eyfSvNeVuzzf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_idx = []  # List to store new indices\n",
        "selected_train_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in train_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(train_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_train_tags.append(t)\n",
        "        new_train_idx.append(index)\n",
        "\n",
        "print(len(new_train_idx))  # Print the length of the new index list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P06sfrbtu2jZ",
        "outputId": "622263e6-1124-4e41-caa6-c9431f1ea536"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_valid_idx = []  # List to store new indices\n",
        "selected_valid_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in valid_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(valid_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_valid_tags.append(t)\n",
        "        new_valid_idx.append(index)\n",
        "\n",
        "print(len(new_valid_idx))  # Print the length of the new index list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUFSB97MsKjs",
        "outputId": "da1251fc-ea88-486b-e632-b1c59411afae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.loc[new_train_idx]\n",
        "train_df['tags'] = selected_train_tags\n",
        "\n",
        "valid_df = valid_df.loc[new_valid_idx]\n",
        "valid_df['tags'] = selected_valid_tags"
      ],
      "metadata": {
        "id": "eWa-EniVu55q"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['description']\n",
        "X_test = valid_df['description']\n",
        "\n",
        "y_tags_train = train_df['tags']\n",
        "y_ratings_train = train_df['rating'].astype(int)\n",
        "\n",
        "y_tags_test = valid_df['tags']\n",
        "y_ratings_test = valid_df['rating'].astype(int)"
      ],
      "metadata": {
        "id": "ztlJ9N1nu5w7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the MultiLabelBinarizer\n",
        "tag_label_encoder = MultiLabelBinarizer()\n",
        "rating_label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder on the labels and transform them\n",
        "y_tags_train = tag_label_encoder.fit_transform(y_tags_train)\n",
        "y_tags_test = tag_label_encoder.transform(y_tags_test)\n",
        "\n",
        "y_ratings_train = rating_label_encoder.fit_transform(y_ratings_train)\n",
        "y_ratings_test = rating_label_encoder.transform(y_ratings_test)"
      ],
      "metadata": {
        "id": "d7Ws7gM6vAKC"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class for multi-label classification head\n",
        "class MultiLabelClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(hidden_size, num_labels)  # Fully connected layer\n",
        "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)  # Apply the fully connected layer\n",
        "        x = self.sigmoid(x)  # Apply the sigmoid activation\n",
        "        return x\n",
        "\n",
        "# Define a class for multi-class classification head\n",
        "class MultiClassClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(hidden_size, num_labels)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)  # Apply the fully connected layer\n",
        "        return x\n",
        "\n",
        "# Define a classifier class\n",
        "class classifier(nn.Module):\n",
        "    def __init__(self, model, device, tags_num_classes, ratings_num_classes):\n",
        "        super().__init__()\n",
        "        self.tags_num_classes = tags_num_classes  # Number of classes for tags\n",
        "        self.ratings_num_classes = ratings_num_classes  # Number of classes for ratings\n",
        "\n",
        "        # Set the device (GPU or CPU)\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize multi-label and multi-class classifiers\n",
        "        self.tags_classifier = MultiLabelClassificationHead(num_labels=self.tags_num_classes).to(self.device)\n",
        "        self.ratings_classifier = MultiClassClassificationHead(num_labels=self.ratings_num_classes).to(self.device)\n",
        "\n",
        "        # Define loss functions for multi-label and multi-class classification\n",
        "        self.BCE = nn.BCELoss().to(self.device)  # Binary Cross Entropy loss for multi-label classification\n",
        "        self.CE = nn.CrossEntropyLoss().to(self.device)  # Cross Entropy loss for multi-class classification\n",
        "\n",
        "        self.model = model\n",
        "        self.lr = config['lr']  # Learning rate\n",
        "        self.parameters = [\n",
        "                {'params': self.model.parameters()},\n",
        "                {'params': self.tags_classifier.parameters()},\n",
        "                {'params': self.ratings_classifier.parameters()}\n",
        "            ]\n",
        "\n",
        "        # Initialize the optimizer\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.parameters,\n",
        "            lr=self.lr\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, tags_labels, ratings_labels):\n",
        "        total_loss = 0\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output  # Pooled output from the model\n",
        "\n",
        "        # Predict tags using the tags classifier\n",
        "        tags_output = self.tags_classifier(pooled_output)\n",
        "        tags_loss = self.BCE(tags_output, tags_labels)  # Calculate the loss for tags\n",
        "\n",
        "        # Predict ratings using the ratings classifier\n",
        "        ratings_output = self.ratings_classifier(pooled_output)\n",
        "        ratings_loss = self.CE(ratings_output, ratings_labels)  # Calculate the loss for ratings\n",
        "\n",
        "        # Calculate the total loss using a sum of tags and ratings loss\n",
        "        total_loss = tags_loss * config['lambda'] + ratings_loss\n",
        "\n",
        "        return total_loss, tags_output, ratings_output"
      ],
      "metadata": {
        "id": "7xKfXH4GvAGS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing(tokenizer, data, max_length):\n",
        "    # Tokenize and encode the text input\n",
        "    data = list(data.values)\n",
        "    tokenized_data = tokenizer(data, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "\n",
        "    return tokenized_data"
      ],
      "metadata": {
        "id": "XKtbMfxhvAEK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tensor(data, dtype):\n",
        "    # Convert data to tensors\n",
        "    tensor_data = torch.tensor(data, dtype=dtype)\n",
        "    return tensor_data"
      ],
      "metadata": {
        "id": "_uc3cNrUvACa"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "import shutil\n",
        "from itertools import chain\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 tokenized_inputs_train,\n",
        "                 tokenized_inputs_test,\n",
        "                 tags_labels_train,\n",
        "                 tags_labels_test,\n",
        "                 ratings_labels_train,\n",
        "                 ratings_labels_test\n",
        "                ):\n",
        "\n",
        "        # Set the device (GPU or CPU)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Store the input data and labels\n",
        "        self.tokenized_inputs_train = tokenized_inputs_train\n",
        "        self.tokenized_inputs_test = tokenized_inputs_test\n",
        "\n",
        "        self.tags_labels_train = tags_labels_train\n",
        "        self.tags_labels_test = tags_labels_test\n",
        "\n",
        "        self.ratings_labels_train = ratings_labels_train\n",
        "        self.ratings_labels_test = ratings_labels_test\n",
        "\n",
        "        # Determine the number of classes for tags and ratings\n",
        "        self.tags_num_classes = len(tags_labels_train[0])\n",
        "        self.ratings_num_classes = len(np.unique(ratings_labels_train))\n",
        "\n",
        "        # Move the model to the specified device\n",
        "        self.model = model.to(self.device)\n",
        "\n",
        "        # Define Classifier Instance\n",
        "        self.classifier_instance = classifier(self.model, self.device, self.tags_num_classes, self.ratings_num_classes)\n",
        "\n",
        "        # Retrieve configuration parameters\n",
        "        self.batch_size = config['batchSize']\n",
        "        self.num_epochs = config['numEpochs']\n",
        "\n",
        "        self.accumulation_steps = config['gradient_accumulation_steps']\n",
        "        self.max_grad_norm = config['max_grad_norm']\n",
        "\n",
        "        self.tag_classes = tag_label_encoder.classes_\n",
        "\n",
        "        self.save = config['save']\n",
        "\n",
        "        # Initialize input data variables\n",
        "        self.input_ids_train = self.tokenized_inputs_train['input_ids']\n",
        "        self.attention_mask_train = self.tokenized_inputs_train['attention_mask']\n",
        "\n",
        "        self.input_ids_test = tokenized_inputs_test['input_ids']\n",
        "        self.attention_mask_test = tokenized_inputs_test['attention_mask']\n",
        "\n",
        "    def train(self):\n",
        "        input_ids_train = self.input_ids_train\n",
        "        attention_mask_train = self.attention_mask_train\n",
        "        tags_labels_train = self.tags_labels_train\n",
        "        ratings_labels_train = self.ratings_labels_train\n",
        "\n",
        "        input_ids_test = self.input_ids_test\n",
        "        attention_mask_test = self.attention_mask_test\n",
        "        tags_labels_test = self.tags_labels_test\n",
        "        ratings_labels_test = self.ratings_labels_test\n",
        "\n",
        "        # Set the optimizer and learning rate\n",
        "        optimizer = self.classifier_instance.optimizer\n",
        "        parameters = self.classifier_instance.parameters\n",
        "\n",
        "        # Set the batch size\n",
        "        batch_size = self.batch_size\n",
        "\n",
        "        # Create a DataLoader for batching the data\n",
        "        train_dataset = TensorDataset(input_ids_train, attention_mask_train, tags_labels_train, ratings_labels_train)\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "        valid_dataset = TensorDataset(input_ids_test, attention_mask_test, tags_labels_test, ratings_labels_test)\n",
        "        valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "        # Set the number of training epochs#\n",
        "        num_epochs = self.num_epochs\n",
        "        device = self.device\n",
        "\n",
        "        model = self.model\n",
        "        classifier_instance = self.classifier_instance\n",
        "\n",
        "        # Training loop\n",
        "        min_loss = 999999\n",
        "        rating_f1_s = 0\n",
        "        total_f1_s = 0\n",
        "        count = 0\n",
        "\n",
        "        #epochs\n",
        "\n",
        "        max_total_f1_macro_score_epochs = 0\n",
        "\n",
        "        max_tag_acc_epochs = 0\n",
        "        max_tag_f1_macro_epochs = 0\n",
        "        max_tag_f1_micro_epochs = 0\n",
        "        max_tag_f1_weighted_epochs= 0\n",
        "        max_tag_f1_samples_epochs= 0\n",
        "        max_tag_roc_auc_score_epochs = 0\n",
        "\n",
        "        max_rating_acc_epochs = 0\n",
        "        max_rating_f1_macro_epochs = 0\n",
        "        max_rating_f1_micro_epochs = 0\n",
        "        max_rating_f1_weighted_epochs= 0\n",
        "\n",
        "        #score\n",
        "        max_total_f1_macro_score = 0\n",
        "\n",
        "        max_tag_acc = 0\n",
        "        max_tag_f1_macro = 0\n",
        "        max_tag_f1_micro = 0\n",
        "        max_tag_f1_weighted = 0\n",
        "        max_tag_f1_samples = 0\n",
        "        max_tag_roc_auc_score = 0\n",
        "\n",
        "        max_rating_acc = 0\n",
        "        max_rating_f1_macro = 0\n",
        "        max_rating_f1_micro = 0\n",
        "        max_rating_f1_weighted = 0\n",
        "\n",
        "        thresholds = [0.001] + [i * 0.01 for i in range(1, 101)]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # set early stopping\n",
        "            #if count > 8:\n",
        "            #    break\n",
        "            train_loss = 0.0\n",
        "            valid_loss = 0.0\n",
        "\n",
        "            tags_true = []\n",
        "            tags_pred = defaultdict(list)\n",
        "            tags_pred_proba = []\n",
        "\n",
        "            ratings_true = []\n",
        "            ratings_pred = []\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            # Training\n",
        "            classifier_instance.train()\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "            for batch in tqdm(train_dataloader):\n",
        "                # Unpack the batch\n",
        "                input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "                # Move the inputs and labels to the chosen device\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                tags_labels = tags_labels.to(device)\n",
        "                ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                loss, _, _ = classifier_instance(input_ids, attention_mask, tags_labels, ratings_labels)\n",
        "                loss /= self.accumulation_steps\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                loss.backward()\n",
        "\n",
        "                if epoch % self.accumulation_steps ==  0 or epoch == batch_size - 1 or self.accumulation_steps == 0:\n",
        "                    if self.max_grad_norm > 0:\n",
        "                        torch.nn.utils.clip_grad_norm_(chain(\n",
        "                            model.parameters(),\n",
        "                            classifier_instance.tags_classifier.parameters(),\n",
        "                            classifier_instance.ratings_classifier.parameters()\n",
        "                        ), self.max_grad_norm)\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # Validation\n",
        "            classifier_instance.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(valid_dataloader):\n",
        "                    # Unpack the batch\n",
        "                    input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "                    # Move the inputs and labels to the chosen device\n",
        "                    input_ids = input_ids.to(device)\n",
        "                    attention_mask = attention_mask.to(device)\n",
        "                    tags_labels = tags_labels.to(device)\n",
        "                    ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    loss, tags_output, ratings_output = classifier_instance(input_ids, attention_mask, tags_labels, ratings_labels)\n",
        "\n",
        "                    valid_loss += loss.item()\n",
        "\n",
        "                    # tags\n",
        "                    tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "\n",
        "                    # Extract indices where the value is above the threshold.\n",
        "                    for threshold in thresholds:\n",
        "                        tags_pred[threshold].extend([(row >= threshold).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "                    tags_true.extend([torch.nonzero(row).flatten().tolist() for row in tags_labels.detach().cpu().clone()])\n",
        "\n",
        "                    ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "                    ratings_true.extend(ratings_labels.detach().cpu().clone())\n",
        "\n",
        "\n",
        "            # Calculate average loss\n",
        "            train_loss /= len(train_dataset)\n",
        "            valid_loss /= len(valid_dataset)\n",
        "\n",
        "\n",
        "            if epoch % self.accumulation_steps ==  0 or epoch == batch_size - 1 or self.accumulation_steps == 0:\n",
        "\n",
        "                # Print the loss, F1 score, precision, and recall for monitoring\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
        "\n",
        "                tag_true = []\n",
        "                #tag_pred = []\n",
        "\n",
        "                rating_true = [tensor.detach().cpu().clone().item() for tensor in ratings_true]\n",
        "                rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "                rating_k = defaultdict(list)\n",
        "\n",
        "                for k in [0, 1, 2]:\n",
        "                    revise_rating_pred = []\n",
        "\n",
        "                    for i in range(len(rating_pred)):\n",
        "                        if abs(rating_true[i] - rating_pred[i]) <= k:\n",
        "                            revise_rating_pred.append(rating_true[i])\n",
        "                        else:\n",
        "                            revise_rating_pred.append(rating_pred[i])\n",
        "                    rating_k[k] = revise_rating_pred\n",
        "\n",
        "                rating_pred = rating_k[1]\n",
        "\n",
        "                rat_t = Counter(rating_true)\n",
        "                rat_p = Counter(rating_pred)\n",
        "\n",
        "                for index_list in tags_true:\n",
        "                    result_true = [0] * self.tags_num_classes  # Create a list of length num_classes.\n",
        "                    for index in index_list:\n",
        "                        result_true[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "                    tag_true.append(result_true)\n",
        "\n",
        "\n",
        "                epoch_max_tag_acc = 0\n",
        "                epoch_max_tag_f1_macro = 0\n",
        "                epoch_max_tag_f1_micro = 0\n",
        "                epoch_max_tag_f1_weighted = 0\n",
        "                epoch_max_tag_f1_samples = 0\n",
        "\n",
        "                epoch_max_rating_acc = 0\n",
        "                epoch_max_rating_f1_macro = 0\n",
        "                epoch_max_rating_f1_micro = 0\n",
        "                epoch_max_rating_f1_weighted = 0\n",
        "\n",
        "                epoch_max_total_f1_macro_score = 0\n",
        "\n",
        "                epoch_max_tag_roc_auc_score = roc_auc_score(tag_true, tags_pred_proba)\n",
        "                tag_true = np.array(tag_true)\n",
        "                tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "                for threshold in thresholds:\n",
        "                    tag_pred = []\n",
        "                    for index_list in tags_pred[threshold]:\n",
        "                        result_pred = [0] * self.tags_num_classes  # Create a list of length num_classes.\n",
        "                        for index in index_list:\n",
        "                            result_pred[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "                        tag_pred.append(result_pred)\n",
        "\n",
        "                    # tag\n",
        "\n",
        "                    tag_acc = accuracy_score(tag_true, tag_pred)\n",
        "                    tag_f1_macro = f1_score(tag_true, tag_pred, average='macro', zero_division=0)\n",
        "                    tag_f1_micro = f1_score(tag_true, tag_pred, average='micro', zero_division=0)\n",
        "                    tag_f1_weighted = f1_score(tag_true, tag_pred, average='weighted', zero_division=0)\n",
        "                    tag_f1_samples = f1_score(tag_true, tag_pred, average='samples', zero_division=0)\n",
        "\n",
        "                    epoch_max_tag_acc = max(epoch_max_tag_acc, tag_acc)\n",
        "                    epoch_max_tag_f1_macro = max(epoch_max_tag_f1_macro, tag_f1_macro)\n",
        "                    epoch_max_tag_f1_micro = max(epoch_max_tag_f1_micro, tag_f1_micro)\n",
        "                    epoch_max_tag_f1_weighted = max(epoch_max_tag_f1_weighted, tag_f1_weighted)\n",
        "                    epoch_max_tag_f1_samples = max(epoch_max_tag_f1_samples, tag_f1_samples)\n",
        "\n",
        "                #tag\n",
        "                print(\"tag acc Max Score in this epoch:\", epoch_max_tag_acc)\n",
        "                print(\"tag valid Max F1 Score(macro) per class in this epoch:\", epoch_max_tag_f1_macro)\n",
        "                print(\"tag valid Max F1 Score(micro) per class in this epoch:\", epoch_max_tag_f1_micro)\n",
        "                print(\"tag valid Max F1 Score(weighted) per class in this epoch:\", epoch_max_tag_f1_weighted)\n",
        "                print(\"tag valid Max F1 Score(samples) per class in this epoch:\", epoch_max_tag_f1_samples)\n",
        "                print()\n",
        "                print(\"tag valid Max roc_auc_score avg in this epoch:\", epoch_max_tag_roc_auc_score)\n",
        "                for num_classes in range(self.tags_num_classes):\n",
        "                    score = roc_auc_score(tag_true[:, num_classes], tags_pred_proba[:, num_classes])\n",
        "                    print(f\"{self.tag_classes[num_classes]} : {score}\")\n",
        "                print()\n",
        "\n",
        "                # rating\n",
        "\n",
        "                for k in [0, 1, 2]:\n",
        "                    rating_pred = rating_k[k]\n",
        "\n",
        "                    rating_acc = accuracy_score(rating_true, rating_pred)\n",
        "                    rating_f1_macro = f1_score(rating_true, rating_pred, average='macro', zero_division=0)\n",
        "                    rating_f1_micro = f1_score(rating_true, rating_pred, average='micro', zero_division=0)\n",
        "                    rating_f1_weighted = f1_score(rating_true, rating_pred, average='weighted', zero_division=0)\n",
        "\n",
        "                    if k == 1:\n",
        "                        epoch_max_rating_acc = max(epoch_max_rating_acc, rating_acc)\n",
        "                        epoch_max_rating_f1_macro = max(epoch_max_rating_f1_macro, rating_f1_macro)\n",
        "                        epoch_max_rating_f1_micro = max(epoch_max_rating_f1_micro, rating_f1_micro)\n",
        "                        epoch_max_rating_f1_weighted = max(epoch_max_rating_f1_weighted, rating_f1_weighted)\n",
        "\n",
        "                    #rating\n",
        "                    print(f\"rating acc Max Score in this epoch at {k}:\", rating_acc)\n",
        "                    print(f\"rating valid Max F1 Score(macro) per class in this epoch at {k}:\", rating_f1_macro)\n",
        "                    print(f\"rating valid Max F1 Score(micro) per class in this epoch at {k}:\", rating_f1_micro)\n",
        "                    print(f\"rating valid Max F1 Score(weighted) per class in this epoch at {k}:\", rating_f1_weighted)\n",
        "                    print()\n",
        "\n",
        "                epoch_max_total_f1_macro_score = (epoch_max_tag_f1_macro + epoch_max_rating_f1_macro) / 2\n",
        "\n",
        "                #rating\n",
        "                print(\"rating acc Max Score in this epoch:\", epoch_max_rating_acc)\n",
        "                print(\"rating valid Max F1 Score(macro) per class in this epoch:\", epoch_max_rating_f1_macro)\n",
        "                print(\"rating valid Max F1 Score(micro) per class in this epoch:\", epoch_max_rating_f1_micro)\n",
        "                print(\"rating valid Max F1 Score(weighted) per class in this epoch:\", epoch_max_rating_f1_weighted)\n",
        "                print()\n",
        "                print('rating_true : ', sorted(rat_t.items(), key=lambda x: x[0]))\n",
        "                print('rating_pred : ', sorted(rat_p.items(), key=lambda x: x[0]))\n",
        "                print()\n",
        "\n",
        "                print(f\"epoch_max_total_f1_score : {epoch_max_total_f1_macro_score}\")\n",
        "                print()\n",
        "\n",
        "                #tag\n",
        "                print(f\"tag acc Max Score: {max_tag_acc} at {max_tag_acc_epochs}epochs\")\n",
        "                print(f\"tag valid Max F1 Score(macro) per class: {max_tag_f1_macro} at {max_tag_f1_macro_epochs}epochs\")\n",
        "                print(f\"tag valid Max F1 Score(micro) per class: {max_tag_f1_micro} at {max_tag_f1_micro_epochs}epochs\")\n",
        "                print(f\"tag valid Max F1 Score(weighted) per class: {max_tag_f1_weighted} at {max_tag_f1_weighted_epochs}epochs\")\n",
        "                print(f\"tag valid Max F1 Score(samples) per class: {max_tag_f1_samples} at {max_tag_f1_samples_epochs}epochs\")\n",
        "                print(f\"tag valid Max roc_auc_score: {max_tag_roc_auc_score} at {max_tag_roc_auc_score_epochs}epochs\")\n",
        "                print()\n",
        "\n",
        "                #rating\n",
        "                print(f\"rating acc Max Score: {max_rating_acc} at {max_rating_acc_epochs}epochs\")\n",
        "                print(f\"rating valid Max F1 Score(macro) per class: {max_rating_f1_macro} at {max_rating_f1_macro_epochs}epochs\")\n",
        "                print(f\"rating valid Max F1 Score(micro) per class: {max_rating_f1_micro} at {max_rating_f1_micro_epochs}epochs\")\n",
        "                print(f\"rating valid Max F1 Score(weighted) per class: {max_rating_f1_weighted} at {max_rating_f1_weighted_epochs}epochs\")\n",
        "                print()\n",
        "\n",
        "                print(f\"prev_max_total_f1_macro_score : {max_total_f1_macro_score}\")\n",
        "\n",
        "                # tag\n",
        "\n",
        "                if epoch_max_tag_acc > max_tag_acc:\n",
        "                    max_tag_acc_epochs = epoch\n",
        "                    max_tag_acc = max(epoch_max_tag_acc, max_tag_acc)\n",
        "\n",
        "                if epoch_max_tag_f1_macro > max_tag_f1_macro:\n",
        "                    max_tag_f1_macro_epochs = epoch\n",
        "                    max_tag_f1_macro = max(epoch_max_tag_f1_macro, max_tag_f1_macro)\n",
        "\n",
        "                    now = datetime.now()\n",
        "                    task = 'total'\n",
        "                    if self.save:\n",
        "                        self.save_checkpoint(task, model, epoch)\n",
        "                    count = 0\n",
        "                    print('Best Model Saved !')\n",
        "                    print()\n",
        "\n",
        "                if epoch_max_tag_f1_micro > max_tag_f1_micro:\n",
        "                    max_tag_f1_micro_epochs = epoch\n",
        "                    max_tag_f1_micro = max(epoch_max_tag_f1_micro, max_tag_f1_micro)\n",
        "\n",
        "                if epoch_max_tag_f1_weighted > max_tag_f1_weighted:\n",
        "                    max_tag_f1_weighted_epochs = epoch\n",
        "                    max_tag_f1_weighted = max(epoch_max_tag_f1_weighted, max_tag_f1_weighted)\n",
        "\n",
        "                if epoch_max_tag_f1_samples > max_tag_f1_samples:\n",
        "                    max_tag_f1_samples_epochs = epoch\n",
        "                    max_tag_f1_samples = max(epoch_max_tag_f1_samples, max_tag_f1_samples)\n",
        "\n",
        "                if epoch_max_tag_roc_auc_score > max_tag_roc_auc_score:\n",
        "                    max_tag_roc_auc_score_epochs = epoch\n",
        "                    max_tag_roc_auc_score = max(epoch_max_tag_roc_auc_score, max_tag_roc_auc_score)\n",
        "\n",
        "                # rating\n",
        "\n",
        "                if epoch_max_rating_acc > max_rating_acc:\n",
        "                    max_rating_acc_epochs = epoch\n",
        "                    max_rating_acc = max(epoch_max_rating_acc, max_rating_acc)\n",
        "\n",
        "                if epoch_max_rating_f1_macro > max_rating_f1_macro:\n",
        "                    max_rating_f1_macro_epochs = epoch\n",
        "                    max_rating_f1_macro = max(epoch_max_rating_f1_macro, max_rating_f1_macro)\n",
        "\n",
        "                if epoch_max_rating_f1_micro > max_rating_f1_micro:\n",
        "                    max_rating_f1_micro_epochs = epoch\n",
        "                    max_rating_f1_micro = max(epoch_max_rating_f1_micro, max_rating_f1_micro)\n",
        "\n",
        "                if epoch_max_rating_f1_weighted > max_rating_f1_weighted:\n",
        "                    max_rating_f1_weighted_epochs = epoch\n",
        "                    max_rating_f1_weighted = max(epoch_max_rating_f1_weighted, max_rating_f1_weighted)\n",
        "\n",
        "                # total\n",
        "\n",
        "                if epoch_max_total_f1_macro_score > max_total_f1_macro_score:\n",
        "                    max_total_f1_macro_score_epochs = epoch\n",
        "                    max_total_f1_macro_score = max(epoch_max_total_f1_macro_score, max_total_f1_macro_score)\n",
        "\n",
        "                print('----------------------------------------------------------------------------')\n",
        "                print()\n",
        "\n",
        "    def save_checkpoint(self, task, model, epoch, max_checkpoints=5):\n",
        "        now = datetime.now()\n",
        "        today = now.strftime('%Y-%m-%d')\n",
        "        checkpoint_filename = f\"{now.strftime('%Y-%m-%d')}_{epoch + 1}\"\n",
        "        checkpoint_path = os.path.join(f\"./models/{task}/{today}\", checkpoint_filename)\n",
        "\n",
        "        # If the directory does not exist, create it.\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            os.makedirs(checkpoint_path)\n",
        "\n",
        "        # Save the model state_dict\n",
        "        torch.save(self.classifier_instance.state_dict(), os.path.join(checkpoint_path, f\"model.pt\"))\n",
        "        checkpoint_files = sorted(os.listdir(f\"./models/{task}/{today}\"))\n",
        "        # Delete oldest checkpoint if there are too many\n",
        "        while len(checkpoint_files) > max_checkpoints + 1:\n",
        "            checkpoint_files = sorted(os.listdir(f\"./models/{task}/{today}\"))\n",
        "            oldest_checkpoint = os.path.join(f\"./models/{task}/{today}\", checkpoint_files[0])\n",
        "            #os.remove(oldest_checkpoint)\n",
        "            if os.path.exists(oldest_checkpoint) and os.path.isdir(oldest_checkpoint):\n",
        "                # Check if the directory is empty, and if not, use shutil.rmtree() to recursively delete it.\n",
        "                try:\n",
        "                    shutil.rmtree(oldest_checkpoint)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error while deleting directory: {e}\")"
      ],
      "metadata": {
        "id": "YchEhVr9vAAa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = config['tokenizer']\n",
        "model = config['model']"
      ],
      "metadata": {
        "id": "yUPB2pWOu_9C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs_train = tokenizing(tokenizer, X_train, config['trainMaxLength'])\n",
        "tokenized_inputs_test = tokenizing(tokenizer, X_test, config['testMaxLength'])"
      ],
      "metadata": {
        "id": "Z9R8zogYu_7M"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_labels_train = convert_to_tensor(y_tags_train, dtype=torch.float)\n",
        "tags_labels_test = convert_to_tensor(y_tags_test, dtype=torch.float)\n",
        "ratings_labels_train = convert_to_tensor(y_ratings_train, dtype=torch.long)\n",
        "ratings_labels_test = convert_to_tensor(y_ratings_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "8Vnbq6IXwBit"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model,\n",
        "                 tokenized_inputs_train,\n",
        "                 tokenized_inputs_test,\n",
        "                 tags_labels_train,\n",
        "                 tags_labels_test,\n",
        "                 ratings_labels_train,\n",
        "                 ratings_labels_test\n",
        "                 )"
      ],
      "metadata": {
        "id": "uJsm43ONwBg2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "Ab0ibW2zwBe1",
        "outputId": "0eb85867-bdee-4437-b5ce-494d87b9e4bd"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  1%|          | 7/1314 [00:14<45:26,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-91ee5cd2e7ef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-b395cbf04ead>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, tags_labels, ratings_labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m  \u001b[0;31m# Pooled output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         )\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   2147\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, band_mask, from_mask, to_mask, blocked_encoder_mask, return_dict)\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 )\n\u001b[1;32m   1639\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1641\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, band_mask, from_mask, to_mask, blocked_encoder_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask)\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BigBird cannot be used as a decoder when config.attention_type != 'original_full'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m             self_outputs = self.self(\n\u001b[0m\u001b[1;32m   1406\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_blocked_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, output_attentions)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         context_layer, attention_probs = self.bigbird_block_sparse_attention(\n\u001b[0m\u001b[1;32m    473\u001b[0m             \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/big_bird/modeling_big_bird.py\u001b[0m in \u001b[0;36mbigbird_block_sparse_attention\u001b[0;34m(self, query_layer, key_layer, value_layer, band_mask, from_mask, to_mask, from_blocked_mask, to_blocked_mask, n_heads, n_rand_blocks, attention_head_size, from_block_size, to_block_size, batch_size, from_seq_len, to_seq_len, seed, plan_from_length, plan_num_rand_blocks, output_attentions)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mrand_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0mrand_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0mrand_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mrand_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrand_attn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "SSpaxri9t7kM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RmF9txecwJWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load('./model.pt') # \"Please input the path to the saved model.\""
      ],
      "metadata": {
        "id": "vY3VGVNcwJUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = {}\n",
        "tag_state_dict = {}\n",
        "rating_state_dict = {}"
      ],
      "metadata": {
        "id": "kcYEAIbOwJRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in state.items():\n",
        "    if \"model.\" in k:\n",
        "        name = k[6:]\n",
        "        model_state_dict[name] = v\n",
        "    if \"tags_classifier.\" in k:\n",
        "        name = k[len(\"tags_classifier.\"):]\n",
        "        tag_state_dict[name] = v\n",
        "    if \"ratings_classifier.\" in k:\n",
        "        name = k[len(\"ratings_classifier.\"):]\n",
        "        rating_state_dict[name] = v"
      ],
      "metadata": {
        "id": "LBG4PFlfwJOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = config['model']\n",
        "tag_head = MultiLabelClassificationHead(10)\n",
        "rating_head = MultiClassClassificationHead(28)"
      ],
      "metadata": {
        "id": "_LXPSeP0wJMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(model_state_dict)\n",
        "tag_head.load_state_dict(tag_state_dict)\n",
        "rating_head.load_state_dict(rating_state_dict)\n",
        "print('fin')"
      ],
      "metadata": {
        "id": "9XSxmn2VwJKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the chosen device\n",
        "model.to(device)\n",
        "tag_head.to(device)\n",
        "rating_head.to(device)\n",
        "print('device : ', device)"
      ],
      "metadata": {
        "id": "OvMI1U2JwJIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = TensorDataset(tokenized_inputs_test['input_ids'], tokenized_inputs_test['attention_mask'], tags_labels_test, ratings_labels_test)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=config['batchSize'], shuffle=False, num_workers=8, pin_memory=True)"
      ],
      "metadata": {
        "id": "9PEtLzYwwMxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "tag_head.eval()\n",
        "rating_head.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    thresholds = [0.001] + [i * 0.01 for i in range(1, 101)]\n",
        "    tags_true = []\n",
        "    tags_pred = defaultdict(list)\n",
        "    tags_pred_proba = []\n",
        "\n",
        "    ratings_true = []\n",
        "    ratings_pred = []\n",
        "    for batch in tqdm(valid_dataloader):\n",
        "        ## Unpack the batch\n",
        "        input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "        # Move the inputs and labels to the chosen device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        tags_labels = tags_labels.to(device)\n",
        "        ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        tags_output = tag_head(pooled_output)\n",
        "        ratings_output = rating_head(pooled_output)\n",
        "\n",
        "        # tags\n",
        "        tags_true.extend([torch.nonzero(row).flatten().tolist() for row in tags_labels.detach().cpu().clone()])\n",
        "        tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "        ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "        ratings_true.extend(ratings_labels.detach().cpu().clone())\n",
        "\n",
        "        # Extract indices with values greater than or equal to the threshold.\n",
        "        for threshold in thresholds:\n",
        "            tags_pred[threshold].extend([(row >= threshold).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "    rating_true = [tensor.detach().cpu().clone().item() for tensor in ratings_true]\n",
        "    rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "    revise_rating_pred = []\n",
        "\n",
        "    for i in range(len(rating_pred)):\n",
        "        if abs(rating_true[i] - rating_pred[i]) <= 1:\n",
        "            revise_rating_pred.append(rating_true[i])\n",
        "        else:\n",
        "            revise_rating_pred.append(rating_pred[i])\n",
        "\n",
        "    rating_pred = revise_rating_pred\n",
        "\n",
        "    tag_true = []\n",
        "\n",
        "    for index_list in tags_true:\n",
        "        result_true = [0] * 10  # Create a list of length num_classes.\n",
        "        for index in index_list:\n",
        "            result_true[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "        tag_true.append(result_true)\n",
        "\n",
        "    tag_true = np.array(tag_true)\n",
        "    tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "    thr = 0\n",
        "    max_f1_score = 0\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        tag_pred = []\n",
        "        for index_list in tags_pred[threshold]:\n",
        "            result_pred = [0] * 10 # Create a list of length num_classes.\n",
        "            for index in index_list:\n",
        "                result_pred[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "            tag_pred.append(result_pred)\n",
        "\n",
        "        f1 = f1_score(tag_true, tag_pred, average='macro', zero_division=0)\n",
        "        if max_f1_score < f1:\n",
        "            thr = threshold\n",
        "            max_f1_score = f1\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "\n",
        "    # Plot ROC curve for each classifier\n",
        "    plt.figure()\n",
        "    for num_classes in range(10):\n",
        "        tt, tp = tag_true[:, num_classes], tags_pred_proba[:, num_classes]\n",
        "\n",
        "        score = roc_auc_score(tt, tp)\n",
        "        tag = tag_label_encoder.classes_[num_classes]\n",
        "        print(f\"{tag} : {score}\")\n",
        "        fpr[num_classes], tpr[num_classes], _ = roc_curve(tt, tp)\n",
        "        plt.plot(fpr[num_classes], tpr[num_classes], label=f'{tag}(area={score:.2f})')\n",
        "    print()\n",
        "\n",
        "    print(\"tag_roc_auc_score : \", roc_auc_score(tag_true, tags_pred_proba))\n",
        "    print(\"f1_score : \", max_f1_score)\n",
        "    print(\"threshold : \", thr)\n",
        "\n",
        "    rating_acc = accuracy_score(rating_true, rating_pred)\n",
        "    print(f\"rating_acc : {rating_acc}\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Tag Prediction')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "eCcOtBhrwNmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zJg1cZRwNkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0bS-_K7wNil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sChODOBMwNg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kZT42GZfwNe9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
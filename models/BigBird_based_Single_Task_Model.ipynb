{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nnpblpm7GVu_",
        "outputId": "d3513008-40c7-48b7-a97c-20977fc63b79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.34.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "#!pip install iterative-stratification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sronger/PSG_Predicting_Algorithm_Tags_and_Difficulty.git"
      ],
      "metadata": {
        "id": "GIzql88DGdBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03f3f7dd-6a6f-4675-e346-50fd1a0c4b1d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'PSG_Predicting_Algorithm_Tags_and_Difficulty' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PSG_Predicting_Algorithm_Tags_and_Difficulty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_H5kmPNuac4",
        "outputId": "0d347bac-56ca-4677-94a5-ee5cd972ba44"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PSG_Predicting_Algorithm_Tags_and_Difficulty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, RobertaTokenizer\n",
        "#from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from collections import Counter, defaultdict\n",
        "import os\n",
        "import shutil\n",
        "from itertools import chain\n",
        "\n",
        "import ast"
      ],
      "metadata": {
        "id": "DD1vmaDKGc_k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./data/AMT10/AMT10_train.csv', index_col=0, encoding='utf8')\n",
        "valid_df = pd.read_csv('./data/AMT10/AMT10_validation.csv', index_col=0, encoding='utf8')\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wQq7WvIHGc9r",
        "outputId": "02d8fee3-f762-4d1f-86b1-ae1e84081209"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              description  \\\n",
              "1845/E  $$$ n $$$ box place a line box number $$$ 1 $$...   \n",
              "1845/B  bob carol hang alice whole day 's time go home...   \n",
              "1845/A  give integer $$$ n $$$ want obtain unlimited s...   \n",
              "1841/B  array $$$ [ a_1 a_2 \\dots a_k ] $$$ call beaut...   \n",
              "1839/A  give two integers $$$ n $$$ $$$ k $$$ array $$...   \n",
              "\n",
              "                                                     tags  rating  \n",
              "1845/E                   ['dp', 'implementation', 'math']  2500.0  \n",
              "1845/B             ['geometry', 'implementation', 'math']   900.0  \n",
              "1845/A  ['constructive algorithms', 'implementation', ...   800.0  \n",
              "1841/B                                 ['implementation']  1000.0  \n",
              "1839/A               ['greedy', 'implementation', 'math']   800.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-88e532a3-7f88-4a8e-a6c4-62dc18df7169\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1845/E</th>\n",
              "      <td>$$$ n $$$ box place a line box number $$$ 1 $$...</td>\n",
              "      <td>['dp', 'implementation', 'math']</td>\n",
              "      <td>2500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845/B</th>\n",
              "      <td>bob carol hang alice whole day 's time go home...</td>\n",
              "      <td>['geometry', 'implementation', 'math']</td>\n",
              "      <td>900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845/A</th>\n",
              "      <td>give integer $$$ n $$$ want obtain unlimited s...</td>\n",
              "      <td>['constructive algorithms', 'implementation', ...</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1841/B</th>\n",
              "      <td>array $$$ [ a_1 a_2 \\dots a_k ] $$$ call beaut...</td>\n",
              "      <td>['implementation']</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839/A</th>\n",
              "      <td>give two integers $$$ n $$$ $$$ k $$$ array $$...</td>\n",
              "      <td>['greedy', 'implementation', 'math']</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e532a3-7f88-4a8e-a6c4-62dc18df7169')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-88e532a3-7f88-4a8e-a6c4-62dc18df7169 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-88e532a3-7f88-4a8e-a6c4-62dc18df7169');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96ef1722-87a1-43fe-a216-44dca3796a45\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96ef1722-87a1-43fe-a216-44dca3796a45')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96ef1722-87a1-43fe-a216-44dca3796a45 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AMT10 = [\n",
        "    'implementation',\n",
        "    'dp',\n",
        "    'math',\n",
        "    'greedy',\n",
        "    'data structures',\n",
        "    'brute force',\n",
        "    'geometry',\n",
        "    'constructive algorithms',\n",
        "    'dfs and similar',\n",
        "    'strings'\n",
        "]"
      ],
      "metadata": {
        "id": "oPQynsyYueoV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = AutoConfig.from_pretrained(\"google/bigbird-roberta-base\", max_position_embeddings=1024)\n",
        "model_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gv2t8fcGc7r",
        "outputId": "1f5d0f7b-ed3b-4203-e690-2f4789f18397"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BigBirdConfig {\n",
              "  \"_name_or_path\": \"google/bigbird-roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"BigBirdForPreTraining\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"attention_type\": \"block_sparse\",\n",
              "  \"block_size\": 64,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu_new\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 1024,\n",
              "  \"model_type\": \"big_bird\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"num_random_blocks\": 3,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"rescale_embeddings\": false,\n",
              "  \"sep_token_id\": 66,\n",
              "  \"transformers_version\": \"4.34.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_bias\": true,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50358\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'seed' : 42,\n",
        "    'tags' : AMT10,\n",
        "    'batchSize' : 4,\n",
        "    'lr' : 5e-6,\n",
        "    'trainMaxLength' : 1024,\n",
        "    'testMaxLength' : 1024,\n",
        "    'numEpochs' : 200,\n",
        "    'model' : AutoModel.from_config(model_config),\n",
        "    'tokenizer' : RobertaTokenizer.from_pretrained('roberta-base'),\n",
        "    'gradient_accumulation_steps' : 4,\n",
        "    'max_grad_norm' : 1.0,\n",
        "    'task' : 'tag', # rating, tag\n",
        "    'lambda' : 10,\n",
        "    'save' : True,\n",
        "}"
      ],
      "metadata": {
        "id": "7jXGJfogGczD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(config['seed'])"
      ],
      "metadata": {
        "id": "uPe4SOKmGcw6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_train_idx = []  # List to store new indices\n",
        "selected_train_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in train_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(train_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_train_tags.append(t)\n",
        "        new_train_idx.append(index)\n",
        "\n",
        "print(len(new_train_idx))  # Print the length of the new index list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdu_ph1GGcus",
        "outputId": "a7f24a6d-ccb7-4f64-ddbe-b458220991d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_valid_idx = []  # List to store new indices\n",
        "selected_valid_tags = []  # List to store selected tags\n",
        "\n",
        "# Iterate through the DataFrame indices\n",
        "for index in valid_df.index:\n",
        "    check = 0\n",
        "    t = []  # List to store selected tags for this index\n",
        "\n",
        "    # Iterate through the tags for the current index\n",
        "    for tag in ast.literal_eval(valid_df.loc[index]['tags']):\n",
        "        if tag in config['tags']:\n",
        "            check = 1\n",
        "            t.append(tag)\n",
        "\n",
        "    # If at least one tag is in the desired tags list, append the index and selected tags\n",
        "    if check == 1:\n",
        "        selected_valid_tags.append(t)\n",
        "        new_valid_idx.append(index)\n",
        "\n",
        "print(len(new_valid_idx))  # Print the length of the new index list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXfztLXQuo0z",
        "outputId": "01a3e3c0-26fd-42ad-eed1-0050e2b7cedc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.loc[new_train_idx]\n",
        "train_df['tags'] = selected_train_tags\n",
        "\n",
        "valid_df = valid_df.loc[new_valid_idx]\n",
        "valid_df['tags'] = selected_valid_tags"
      ],
      "metadata": {
        "id": "VZBEzsKRuqS4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df['description']\n",
        "X_test = valid_df['description']\n",
        "\n",
        "y_tags_train = train_df['tags']\n",
        "y_ratings_train = train_df['rating'].astype(int)\n",
        "\n",
        "y_tags_test = valid_df['tags']\n",
        "y_ratings_test = valid_df['rating'].astype(int)"
      ],
      "metadata": {
        "id": "ZK1NGl5OKfUk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the MultiLabelBinarizer\n",
        "tag_label_encoder = MultiLabelBinarizer()\n",
        "rating_label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the label encoder on the labels and transform them\n",
        "y_tags_train = tag_label_encoder.fit_transform(y_tags_train)\n",
        "y_tags_test = tag_label_encoder.transform(y_tags_test)\n",
        "\n",
        "y_ratings_train = rating_label_encoder.fit_transform(y_ratings_train)\n",
        "y_ratings_test = rating_label_encoder.transform(y_ratings_test)"
      ],
      "metadata": {
        "id": "Kf1HtDq_Gcpz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a class for multi-label classification head\n",
        "class MultiLabelClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size) # Fully connected layer\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size) # Fully connected layer\n",
        "        self.fc3 = nn.Linear(hidden_size, num_labels) # Fully connected layer\n",
        "        self.sigmoid = nn.Sigmoid() # Sigmoid activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x) # Apply the fully connected layer\n",
        "        x = self.fc2(x) # Apply the fully connected layer\n",
        "        x = self.fc3(x) # Apply the fully connected layer\n",
        "        x = self.sigmoid(x) # Apply the sigmoid activation\n",
        "        return x\n",
        "\n",
        "# Define a class for multi-class classification head\n",
        "class MultiClassClassificationHead(nn.Module):\n",
        "    def __init__(self, num_labels, hidden_size=768):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(hidden_size, num_labels)  # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)  # Apply the fully connected layer\n",
        "        return x\n",
        "\n",
        "# Define a classifier class\n",
        "class classifier(nn.Module):\n",
        "    def __init__(self, model, device, tags_num_classes, ratings_num_classes):\n",
        "        super().__init__()\n",
        "        self.tags_num_classes = tags_num_classes  # Number of classes for tags\n",
        "        self.ratings_num_classes = ratings_num_classes  # Number of classes for ratings\n",
        "\n",
        "        # Set the device (GPU or CPU)\n",
        "        self.device = device\n",
        "\n",
        "        # Initialize multi-label and multi-class classifiers\n",
        "        self.tags_classifier = MultiLabelClassificationHead(num_labels=self.tags_num_classes).to(self.device)\n",
        "        self.ratings_classifier = MultiClassClassificationHead(num_labels=self.ratings_num_classes).to(self.device)\n",
        "\n",
        "        # Define loss functions for multi-label and multi-class classification\n",
        "        self.BCE = nn.BCELoss().to(self.device)  # Binary Cross Entropy loss for multi-label classification\n",
        "        self.CE = nn.CrossEntropyLoss().to(self.device)  # Cross Entropy loss for multi-class classification\n",
        "\n",
        "        self.model = model\n",
        "        self.lr = config['lr']\n",
        "        self.task = config['task']\n",
        "\n",
        "        if self.task == 'tag':\n",
        "            self.parameters = [\n",
        "                    {'params': self.model.parameters()},\n",
        "                    {'params': self.tags_classifier.parameters()},\n",
        "                ]\n",
        "        elif self.task == 'rating':\n",
        "            self.parameters = [\n",
        "                    {'params': self.model.parameters()},\n",
        "                    {'params': self.ratings_classifier.parameters()}\n",
        "                ]\n",
        "\n",
        "        # Initialize the optimizer\n",
        "        self.optimizer = torch.optim.Adam(\n",
        "            self.parameters,\n",
        "            lr=self.lr\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, tags_labels, ratings_labels):\n",
        "\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output # Pooled output from the model\n",
        "\n",
        "        if self.task == 'tag':\n",
        "          output = self.tags_classifier(pooled_output) # Predict tags using the tags classifier\n",
        "          loss = self.BCE(output, tags_labels) # Calculate the loss for tags\n",
        "        elif self.task == 'rating':\n",
        "          output = self.ratings_classifier(pooled_output) # Predict ratings using the ratings classifier\n",
        "          loss = self.CE(output, ratings_labels) # Calculate the loss for ratings\n",
        "\n",
        "        return loss, output"
      ],
      "metadata": {
        "id": "YL7tlJ1eGcly"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizing(tokenizer, data, max_length):\n",
        "    # Tokenize and encode the text input\n",
        "    data = list(data.values)\n",
        "    tokenized_data = tokenizer(data, padding=True, truncation=True, return_tensors='pt', max_length=max_length)\n",
        "\n",
        "    return tokenized_data"
      ],
      "metadata": {
        "id": "MOXiQD3wGcjz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tensor(data, dtype):\n",
        "    # Convert data to tensors\n",
        "    tensor_data = torch.tensor(data, dtype=dtype)\n",
        "    return tensor_data"
      ],
      "metadata": {
        "id": "CguouZ5RGchr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 tokenized_inputs_train,\n",
        "                 tokenized_inputs_test,\n",
        "                 tags_labels_train,\n",
        "                 tags_labels_test,\n",
        "                 ratings_labels_train,\n",
        "                 ratings_labels_test\n",
        "                ):\n",
        "        # Set the device (GPU or CPU)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        # Store the input data and labels\n",
        "        self.tokenized_inputs_train = tokenized_inputs_train\n",
        "        self.tokenized_inputs_test = tokenized_inputs_test\n",
        "\n",
        "        self.tags_labels_train = tags_labels_train\n",
        "        self.tags_labels_test = tags_labels_test\n",
        "\n",
        "        self.ratings_labels_train = ratings_labels_train\n",
        "        self.ratings_labels_test = ratings_labels_test\n",
        "\n",
        "        # Determine the number of classes for tags and ratings\n",
        "        self.tags_num_classes = len(tags_labels_train[0])\n",
        "        self.ratings_num_classes = len(np.unique(ratings_labels_train))\n",
        "\n",
        "        # Move the model to the specified device\n",
        "        self.model = model.to(self.device)\n",
        "\n",
        "        # Define Classifier Instance\n",
        "        self.classifier_instance = classifier(self.model, self.device, self.tags_num_classes, self.ratings_num_classes)\n",
        "\n",
        "        # Retrieve configuration parameters\n",
        "        self.batch_size = config['batchSize']\n",
        "        self.num_epochs = config['numEpochs']\n",
        "\n",
        "        self.accumulation_steps = config['gradient_accumulation_steps']\n",
        "        self.max_grad_norm = config['max_grad_norm']\n",
        "\n",
        "        self.tag_classes = tag_label_encoder.classes_\n",
        "\n",
        "        self.save = config['save']\n",
        "\n",
        "        # Initialize input data variables\n",
        "        self.input_ids_train = self.tokenized_inputs_train['input_ids']\n",
        "        self.attention_mask_train = self.tokenized_inputs_train['attention_mask']\n",
        "\n",
        "        self.input_ids_test = tokenized_inputs_test['input_ids']\n",
        "        self.attention_mask_test = tokenized_inputs_test['attention_mask']\n",
        "\n",
        "        self.task = config['task']\n",
        "\n",
        "    def train(self):\n",
        "        input_ids_train = self.input_ids_train\n",
        "        attention_mask_train = self.attention_mask_train\n",
        "        tags_labels_train = self.tags_labels_train\n",
        "        ratings_labels_train = self.ratings_labels_train\n",
        "\n",
        "        input_ids_test = self.input_ids_test\n",
        "        attention_mask_test = self.attention_mask_test\n",
        "        tags_labels_test = self.tags_labels_test\n",
        "        ratings_labels_test = self.ratings_labels_test\n",
        "\n",
        "        # Set the optimizer and learning rate\n",
        "        optimizer = self.classifier_instance.optimizer\n",
        "        parameters = self.classifier_instance.parameters\n",
        "\n",
        "        # Set the batch size\n",
        "        batch_size = self.batch_size\n",
        "\n",
        "        # Create a DataLoader for batching the data\n",
        "        train_dataset = TensorDataset(input_ids_train, attention_mask_train, tags_labels_train, ratings_labels_train)\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8, pin_memory=True)\n",
        "\n",
        "        valid_dataset = TensorDataset(input_ids_test, attention_mask_test, tags_labels_test, ratings_labels_test)\n",
        "        valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "        # Set the number of training epochs#\n",
        "        num_epochs = self.num_epochs\n",
        "        device = self.device\n",
        "\n",
        "        model = self.model\n",
        "        classifier_instance = self.classifier_instance\n",
        "\n",
        "        # Training loop\n",
        "        min_loss = 999999\n",
        "        rating_f1_s = 0\n",
        "        total_f1_s = 0\n",
        "        count = 0\n",
        "\n",
        "        #epochs\n",
        "\n",
        "        max_total_f1_macro_score_epochs = 0\n",
        "\n",
        "        max_tag_acc_epochs = 0\n",
        "        max_tag_f1_macro_epochs = 0\n",
        "        max_tag_f1_micro_epochs = 0\n",
        "        max_tag_f1_weighted_epochs= 0\n",
        "        max_tag_f1_samples_epochs= 0\n",
        "        max_tag_roc_auc_score_epochs = 0\n",
        "\n",
        "        max_rating_acc_epochs = 0\n",
        "        max_rating_f1_macro_epochs = 0\n",
        "        max_rating_f1_micro_epochs = 0\n",
        "        max_rating_f1_weighted_epochs= 0\n",
        "\n",
        "        #score\n",
        "        max_total_f1_macro_score = 0\n",
        "\n",
        "        max_tag_acc = 0\n",
        "        max_tag_f1_macro = 0\n",
        "        max_tag_f1_micro = 0\n",
        "        max_tag_f1_weighted = 0\n",
        "        max_tag_f1_samples = 0\n",
        "        max_tag_roc_auc_score = 0\n",
        "\n",
        "        max_rating_acc = 0\n",
        "        max_rating_f1_macro = 0\n",
        "        max_rating_f1_micro = 0\n",
        "        max_rating_f1_weighted = 0\n",
        "\n",
        "        thresholds = [0.001] + [i * 0.01 for i in range(1, 101)]\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # set early stopping\n",
        "            #if count > 8:\n",
        "            #    break\n",
        "            train_loss = 0.0\n",
        "            valid_loss = 0.0\n",
        "\n",
        "            tags_true = []\n",
        "            tags_pred = defaultdict(list)\n",
        "            tags_pred_proba = []\n",
        "\n",
        "            ratings_true = []\n",
        "            ratings_pred = []\n",
        "\n",
        "            count += 1\n",
        "\n",
        "            # Training\n",
        "            classifier_instance.train()\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "            for batch in tqdm(train_dataloader):\n",
        "                # Unpack the batch\n",
        "                input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "                # Move the inputs and labels to the chosen device\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                tags_labels = tags_labels.to(device)\n",
        "                ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                loss, _ = classifier_instance(input_ids, attention_mask, tags_labels, ratings_labels)\n",
        "                loss /= self.accumulation_steps\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                loss.backward()\n",
        "\n",
        "                if epoch % self.accumulation_steps ==  0 or epoch == batch_size - 1 or self.accumulation_steps == 0:\n",
        "                    if self.max_grad_norm > 0:\n",
        "\n",
        "                        if self.task == 'tag':\n",
        "                            torch.nn.utils.clip_grad_norm_(chain(\n",
        "                                model.parameters(),\n",
        "                                classifier_instance.tags_classifier.parameters()\n",
        "                            ), self.max_grad_norm)\n",
        "                        elif self.task == 'rating':\n",
        "                            torch.nn.utils.clip_grad_norm_(chain(\n",
        "                                model.parameters(),\n",
        "                                classifier_instance.ratings_classifier.parameters()\n",
        "                            ), self.max_grad_norm)\n",
        "                    optimizer.step()\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "            # Validation\n",
        "            #model.eval()\n",
        "            classifier_instance.eval()\n",
        "            with torch.no_grad():\n",
        "                for batch in tqdm(valid_dataloader):\n",
        "                    # Unpack the batch\n",
        "                    input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "                    # Move the inputs and labels to the chosen device\n",
        "                    input_ids = input_ids.to(device)\n",
        "                    attention_mask = attention_mask.to(device)\n",
        "                    tags_labels = tags_labels.to(device)\n",
        "                    ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    loss, output = classifier_instance(input_ids, attention_mask, tags_labels, ratings_labels)\n",
        "\n",
        "                    valid_loss += loss.item()\n",
        "\n",
        "                    if self.task == 'tag':\n",
        "                        tags_output = output\n",
        "\n",
        "                        # tags\n",
        "                        tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "                        # Extract indices where the value is above the threshold.\n",
        "                        for threshold in thresholds:\n",
        "                            tags_pred[threshold].extend([(row >= threshold).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "                        tags_true.extend([torch.nonzero(row).flatten().tolist() for row in tags_labels.detach().cpu().clone()])\n",
        "                    elif self.task == 'rating':\n",
        "\n",
        "                        ratings_output = output\n",
        "\n",
        "                        ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "                        ratings_true.extend(ratings_labels.detach().cpu().clone())\n",
        "\n",
        "\n",
        "            # Calculate average loss\n",
        "            train_loss /= len(train_dataset)\n",
        "            valid_loss /= len(valid_dataset)\n",
        "\n",
        "\n",
        "            if epoch % self.accumulation_steps ==  0 or epoch == batch_size - 1 or self.accumulation_steps == 0:\n",
        "\n",
        "                # Print the loss, F1 score, precision, and recall for monitoring\n",
        "                print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}\")\n",
        "\n",
        "                tag_true = []\n",
        "                #tag_pred = []\n",
        "\n",
        "                if self.task == 'rating':\n",
        "\n",
        "                    rating_true = [tensor.detach().cpu().clone().item() for tensor in ratings_true]\n",
        "                    rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "                    rating_k = defaultdict(list)\n",
        "\n",
        "                    for k in [0, 1, 2]:\n",
        "                        revise_rating_pred = []\n",
        "\n",
        "                        for i in range(len(rating_pred)):\n",
        "                            if abs(rating_true[i] - rating_pred[i]) <= k:\n",
        "                                revise_rating_pred.append(rating_true[i])\n",
        "                            else:\n",
        "                                revise_rating_pred.append(rating_pred[i])\n",
        "                        rating_k[k] = revise_rating_pred\n",
        "\n",
        "                    rating_pred = rating_k[1]\n",
        "\n",
        "                    rat_t = Counter(rating_true)\n",
        "                    rat_p = Counter(rating_pred)\n",
        "\n",
        "                    epoch_max_rating_acc = 0\n",
        "                    epoch_max_rating_f1_macro = 0\n",
        "                    epoch_max_rating_f1_micro = 0\n",
        "                    epoch_max_rating_f1_weighted = 0\n",
        "\n",
        "                    # rating\n",
        "\n",
        "                    for k in [0, 1, 2]:\n",
        "                        rating_pred = rating_k[k]\n",
        "\n",
        "                        rating_acc = accuracy_score(rating_true, rating_pred)\n",
        "                        rating_f1_macro = f1_score(rating_true, rating_pred, average='macro', zero_division=0)\n",
        "                        rating_f1_micro = f1_score(rating_true, rating_pred, average='micro', zero_division=0)\n",
        "                        rating_f1_weighted = f1_score(rating_true, rating_pred, average='weighted', zero_division=0)\n",
        "\n",
        "                        if k == 1:\n",
        "                            epoch_max_rating_acc = max(epoch_max_rating_acc, rating_acc)\n",
        "                            epoch_max_rating_f1_macro = max(epoch_max_rating_f1_macro, rating_f1_macro)\n",
        "                            epoch_max_rating_f1_micro = max(epoch_max_rating_f1_micro, rating_f1_micro)\n",
        "                            epoch_max_rating_f1_weighted = max(epoch_max_rating_f1_weighted, rating_f1_weighted)\n",
        "\n",
        "                        #rating\n",
        "                        print(f\"rating acc Max Score in this epoch at {k}:\", rating_acc)\n",
        "                        print(f\"rating valid Max F1 Score(macro) per class in this epoch at {k}:\", rating_f1_macro)\n",
        "                        print(f\"rating valid Max F1 Score(micro) per class in this epoch at {k}:\", rating_f1_micro)\n",
        "                        print(f\"rating valid Max F1 Score(weighted) per class in this epoch at {k}:\", rating_f1_weighted)\n",
        "                        print()\n",
        "\n",
        "                    #rating\n",
        "                    print(\"rating acc Max Score in this epoch:\", epoch_max_rating_acc)\n",
        "                    print(\"rating valid Max F1 Score(macro) per class in this epoch:\", epoch_max_rating_f1_macro)\n",
        "                    print(\"rating valid Max F1 Score(micro) per class in this epoch:\", epoch_max_rating_f1_micro)\n",
        "                    print(\"rating valid Max F1 Score(weighted) per class in this epoch:\", epoch_max_rating_f1_weighted)\n",
        "                    print()\n",
        "                    print('rating_true : ', sorted(rat_t.items(), key=lambda x: x[0]))\n",
        "                    print('rating_pred : ', sorted(rat_p.items(), key=lambda x: x[0]))\n",
        "                    print()\n",
        "\n",
        "\n",
        "                    #rating\n",
        "                    print(f\"rating acc Max Score: {max_rating_acc} at {max_rating_acc_epochs}epochs\")\n",
        "                    print(f\"rating valid Max F1 Score(macro) per class: {max_rating_f1_macro} at {max_rating_f1_macro_epochs}epochs\")\n",
        "                    print(f\"rating valid Max F1 Score(micro) per class: {max_rating_f1_micro} at {max_rating_f1_micro_epochs}epochs\")\n",
        "                    print(f\"rating valid Max F1 Score(weighted) per class: {max_rating_f1_weighted} at {max_rating_f1_weighted_epochs}epochs\")\n",
        "                    print()\n",
        "\n",
        "                    # rating\n",
        "\n",
        "                    if epoch_max_rating_acc > max_rating_acc:\n",
        "                        max_rating_acc_epochs = epoch\n",
        "                        max_rating_acc = max(epoch_max_rating_acc, max_rating_acc)\n",
        "\n",
        "                    if epoch_max_rating_f1_macro > max_rating_f1_macro:\n",
        "                        max_rating_f1_macro_epochs = epoch\n",
        "                        max_rating_f1_macro = max(epoch_max_rating_f1_macro, max_rating_f1_macro)\n",
        "\n",
        "                        now = datetime.now()\n",
        "                        task = config['task']\n",
        "                        if self.save:\n",
        "                            self.save_checkpoint(task, model, epoch)\n",
        "                        count = 0\n",
        "                        print('Best Model Saved !')\n",
        "                        print()\n",
        "\n",
        "                    if epoch_max_rating_f1_micro > max_rating_f1_micro:\n",
        "                        max_rating_f1_micro_epochs = epoch\n",
        "                        max_rating_f1_micro = max(epoch_max_rating_f1_micro, max_rating_f1_micro)\n",
        "\n",
        "                    if epoch_max_rating_f1_weighted > max_rating_f1_weighted:\n",
        "                        max_rating_f1_weighted_epochs = epoch\n",
        "                        max_rating_f1_weighted = max(epoch_max_rating_f1_weighted, max_rating_f1_weighted)\n",
        "\n",
        "                elif self.task == 'tag':\n",
        "\n",
        "                    for index_list in tags_true:\n",
        "                        result_true = [0] * self.tags_num_classes  # Create a list of length num_classes.\n",
        "                        for index in index_list:\n",
        "                            result_true[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "                        tag_true.append(result_true)\n",
        "\n",
        "\n",
        "                    epoch_max_tag_acc = 0\n",
        "                    epoch_max_tag_f1_macro = 0\n",
        "                    epoch_max_tag_f1_micro = 0\n",
        "                    epoch_max_tag_f1_weighted = 0\n",
        "                    epoch_max_tag_f1_samples = 0\n",
        "\n",
        "                    epoch_max_tag_roc_auc_score = roc_auc_score(tag_true, tags_pred_proba)\n",
        "                    tag_true = np.array(tag_true)\n",
        "                    tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "                    for threshold in thresholds:\n",
        "                        tag_pred = []\n",
        "                        for index_list in tags_pred[threshold]:\n",
        "                            result_pred = [0] * self.tags_num_classes  # Create a list of length num_classes.\n",
        "                            for index in index_list:\n",
        "                                result_pred[index] = 1 # Fill the corresponding index with 1.\n",
        "\n",
        "                            tag_pred.append(result_pred)\n",
        "\n",
        "                        # tag\n",
        "\n",
        "                        tag_acc = accuracy_score(tag_true, tag_pred)\n",
        "                        tag_f1_macro = f1_score(tag_true, tag_pred, average='macro', zero_division=0)\n",
        "                        tag_f1_micro = f1_score(tag_true, tag_pred, average='micro', zero_division=0)\n",
        "                        tag_f1_weighted = f1_score(tag_true, tag_pred, average='weighted', zero_division=0)\n",
        "                        tag_f1_samples = f1_score(tag_true, tag_pred, average='samples', zero_division=0)\n",
        "\n",
        "                        epoch_max_tag_acc = max(epoch_max_tag_acc, tag_acc)\n",
        "                        epoch_max_tag_f1_macro = max(epoch_max_tag_f1_macro, tag_f1_macro)\n",
        "                        epoch_max_tag_f1_micro = max(epoch_max_tag_f1_micro, tag_f1_micro)\n",
        "                        epoch_max_tag_f1_weighted = max(epoch_max_tag_f1_weighted, tag_f1_weighted)\n",
        "                        epoch_max_tag_f1_samples = max(epoch_max_tag_f1_samples, tag_f1_samples)\n",
        "\n",
        "                    #tag\n",
        "                    print(\"tag acc Max Score in this epoch:\", epoch_max_tag_acc)\n",
        "                    print(\"tag valid Max F1 Score(macro) per class in this epoch:\", epoch_max_tag_f1_macro)\n",
        "                    print(\"tag valid Max F1 Score(micro) per class in this epoch:\", epoch_max_tag_f1_micro)\n",
        "                    print(\"tag valid Max F1 Score(weighted) per class in this epoch:\", epoch_max_tag_f1_weighted)\n",
        "                    print(\"tag valid Max F1 Score(samples) per class in this epoch:\", epoch_max_tag_f1_samples)\n",
        "                    print()\n",
        "                    print(\"tag valid Max roc_auc_score avg in this epoch:\", epoch_max_tag_roc_auc_score)\n",
        "\n",
        "                    for num_classes in range(self.tags_num_classes):\n",
        "                        score = roc_auc_score(tag_true[:, num_classes], tags_pred_proba[:, num_classes])\n",
        "                        print(f\"{self.tag_classes[num_classes]} : {score}\")\n",
        "                    print()\n",
        "\n",
        "                    #tag\n",
        "                    print(f\"tag acc Max Score: {max_tag_acc} at {max_tag_acc_epochs}epochs\")\n",
        "                    print(f\"tag valid Max F1 Score(macro) per class: {max_tag_f1_macro} at {max_tag_f1_macro_epochs}epochs\")\n",
        "                    print(f\"tag valid Max F1 Score(micro) per class: {max_tag_f1_micro} at {max_tag_f1_micro_epochs}epochs\")\n",
        "                    print(f\"tag valid Max F1 Score(weighted) per class: {max_tag_f1_weighted} at {max_tag_f1_weighted_epochs}epochs\")\n",
        "                    print(f\"tag valid Max F1 Score(samples) per class: {max_tag_f1_samples} at {max_tag_f1_samples_epochs}epochs\")\n",
        "                    print(f\"tag valid Max roc_auc_score: {max_tag_roc_auc_score} at {max_tag_roc_auc_score_epochs}epochs\")\n",
        "                    print()\n",
        "\n",
        "                    # tag\n",
        "\n",
        "                    if epoch_max_tag_acc > max_tag_acc:\n",
        "                        max_tag_acc_epochs = epoch\n",
        "                        max_tag_acc = max(epoch_max_tag_acc, max_tag_acc)\n",
        "\n",
        "                    if epoch_max_tag_f1_macro > max_tag_f1_macro:\n",
        "                        max_tag_f1_macro_epochs = epoch\n",
        "                        max_tag_f1_macro = max(epoch_max_tag_f1_macro, max_tag_f1_macro)\n",
        "\n",
        "                        now = datetime.now()\n",
        "                        task = config['task']\n",
        "                        if self.save:\n",
        "                            self.save_checkpoint(task, model, epoch)\n",
        "                        count = 0\n",
        "                        print('Best Model Saved !')\n",
        "                        print()\n",
        "\n",
        "                    if epoch_max_tag_f1_micro > max_tag_f1_micro:\n",
        "                        max_tag_f1_micro_epochs = epoch\n",
        "                        max_tag_f1_micro = max(epoch_max_tag_f1_micro, max_tag_f1_micro)\n",
        "\n",
        "                    if epoch_max_tag_f1_weighted > max_tag_f1_weighted:\n",
        "                        max_tag_f1_weighted_epochs = epoch\n",
        "                        max_tag_f1_weighted = max(epoch_max_tag_f1_weighted, max_tag_f1_weighted)\n",
        "\n",
        "                    if epoch_max_tag_f1_samples > max_tag_f1_samples:\n",
        "                        max_tag_f1_samples_epochs = epoch\n",
        "                        max_tag_f1_samples = max(epoch_max_tag_f1_samples, max_tag_f1_samples)\n",
        "\n",
        "                    if epoch_max_tag_roc_auc_score > max_tag_roc_auc_score:\n",
        "                        max_tag_roc_auc_score_epochs = epoch\n",
        "                        max_tag_roc_auc_score = max(epoch_max_tag_roc_auc_score, max_tag_roc_auc_score)\n",
        "\n",
        "                print('----------------------------------------------------------------------------')\n",
        "                print()\n",
        "\n",
        "    def save_checkpoint(self, task, model, epoch, max_checkpoints=5):\n",
        "        now = datetime.now()\n",
        "        today = now.strftime('%Y-%m-%d')\n",
        "        checkpoint_filename = f\"{now.strftime('%Y-%m-%d')}_{epoch + 1}\"\n",
        "        checkpoint_path = os.path.join(f\"./models/{task}/{today}\", checkpoint_filename)\n",
        "\n",
        "        # If the directory does not exist, create it.\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            os.makedirs(checkpoint_path)\n",
        "\n",
        "        # Save the model state_dict\n",
        "        torch.save(self.classifier_instance.state_dict(), os.path.join(checkpoint_path, f\"model.pt\"))\n",
        "        checkpoint_files = sorted(os.listdir(f\"./models/{task}/{today}\"))\n",
        "        # Delete oldest checkpoint if there are too many\n",
        "        while len(checkpoint_files) > max_checkpoints + 1:\n",
        "            checkpoint_files = sorted(os.listdir(f\"./models/{task}/{today}\"))\n",
        "            oldest_checkpoint = os.path.join(f\"./models/{task}/{today}\", checkpoint_files[0])\n",
        "            #os.remove(oldest_checkpoint)\n",
        "            if os.path.exists(oldest_checkpoint) and os.path.isdir(oldest_checkpoint):\n",
        "                # Check if the directory is empty, and if not, use shutil.rmtree() to recursively delete it.\n",
        "                try:\n",
        "                    shutil.rmtree(oldest_checkpoint)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error while deleting directory: {e}\")"
      ],
      "metadata": {
        "id": "onmwykhkGcfq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = config['tokenizer']\n",
        "model = config['model']"
      ],
      "metadata": {
        "id": "OYL4JnAxGcdb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_inputs_train = tokenizing(tokenizer, X_train, config['trainMaxLength'])\n",
        "tokenized_inputs_test = tokenizing(tokenizer, X_test, config['testMaxLength'])"
      ],
      "metadata": {
        "id": "Ppu5jEkjGcbj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags_labels_train = convert_to_tensor(y_tags_train, dtype=torch.float)\n",
        "tags_labels_test = convert_to_tensor(y_tags_test, dtype=torch.float)\n",
        "ratings_labels_train = convert_to_tensor(y_ratings_train, dtype=torch.long)\n",
        "ratings_labels_test = convert_to_tensor(y_ratings_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "HaNnefJtGcZa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model,\n",
        "                 tokenized_inputs_train,\n",
        "                 tokenized_inputs_test,\n",
        "                 tags_labels_train,\n",
        "                 tags_labels_test,\n",
        "                 ratings_labels_train,\n",
        "                 ratings_labels_test\n",
        "                 )"
      ],
      "metadata": {
        "id": "9T-aDDKjGcXc"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "JHU5bFOBGcVL",
        "outputId": "47431e7e-c9f3-4b1f-a683-947332c6a0f6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "  2%|▏         | 23/1314 [00:35<32:45,  1.52s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-178cb6eeb292>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# Backward pass and optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m  \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "gkrYhqpMv2bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7HDvJZO5GcTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load('./model.pt')"
      ],
      "metadata": {
        "id": "H9iQ3T9uGcQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = {}\n",
        "tag_state_dict = {}\n",
        "rating_state_dict = {}"
      ],
      "metadata": {
        "id": "M9a71eeQGcOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in state.items():\n",
        "    if \"model.\" in k:\n",
        "        name = k[6:]\n",
        "        model_state_dict[name] = v\n",
        "    if \"tags_classifier.\" in k:\n",
        "        name = k[len(\"tags_classifier.\"):]\n",
        "        tag_state_dict[name] = v\n",
        "    if \"ratings_classifier.\" in k:\n",
        "        name = k[len(\"ratings_classifier.\"):]\n",
        "        rating_state_dict[name] = v"
      ],
      "metadata": {
        "id": "IEZTgWXLGcMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = config['model']\n",
        "tag_head = MultiLabelClassificationHead(10)\n",
        "rating_head = MultiClassClassificationHead(28)"
      ],
      "metadata": {
        "id": "y_DSrqetGcKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(model_state_dict)\n",
        "tag_head.load_state_dict(tag_state_dict)\n",
        "rating_head.load_state_dict(rating_state_dict)\n",
        "print('fin')"
      ],
      "metadata": {
        "id": "gMzigxAdGcIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device (GPU or CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Move the model to the chosen device\n",
        "model.to(device)\n",
        "tag_head.to(device)\n",
        "rating_head.to(device)\n",
        "print('device : ', device)"
      ],
      "metadata": {
        "id": "JlLSK8NBK6cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = TensorDataset(tokenized_inputs_test['input_ids'], tokenized_inputs_test['attention_mask'], tags_labels_test, ratings_labels_test)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=config['batchSize'], shuffle=False, num_workers=8, pin_memory=True)"
      ],
      "metadata": {
        "id": "AH2-JiW0K6am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "tag_head.eval()\n",
        "rating_head.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    thresholds = [0.001] + [i * 0.01 for i in range(1, 101)]\n",
        "    tags_true = []\n",
        "    tags_pred = defaultdict(list)\n",
        "    tags_pred_proba = []\n",
        "\n",
        "    ratings_true = []\n",
        "    ratings_pred = []\n",
        "    for batch in tqdm(valid_dataloader):\n",
        "        ## Unpack the batch\n",
        "        input_ids, attention_mask, tags_labels, ratings_labels = batch\n",
        "\n",
        "        # Move the inputs and labels to the chosen device\n",
        "        input_ids = input_ids.to(device)\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        tags_labels = tags_labels.to(device)\n",
        "        ratings_labels = ratings_labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "\n",
        "        tags_output = tag_head(pooled_output)\n",
        "        ratings_output = rating_head(pooled_output)\n",
        "\n",
        "        # tags\n",
        "        tags_true.extend([torch.nonzero(row).flatten().tolist() for row in tags_labels.detach().cpu().clone()])\n",
        "        tags_pred_proba.extend(tags_output.detach().cpu().clone().tolist())\n",
        "\n",
        "        ratings_pred.extend(torch.argmax(ratings_output, dim=1).detach().cpu().clone())\n",
        "        ratings_true.extend(ratings_labels.detach().cpu().clone())\n",
        "\n",
        "        # Extract indices with values greater than or equal to the threshold.\n",
        "        for threshold in thresholds:\n",
        "            tags_pred[threshold].extend([(row >= threshold).nonzero().flatten().tolist() for row in tags_output.detach().cpu().clone()])\n",
        "\n",
        "    rating_true = [tensor.detach().cpu().clone().item() for tensor in ratings_true]\n",
        "    rating_pred = [tensor.detach().cpu().clone().item() for tensor in ratings_pred]\n",
        "\n",
        "    revise_rating_pred = []\n",
        "\n",
        "    for i in range(len(rating_pred)):\n",
        "        if abs(rating_true[i] - rating_pred[i]) <= 1:\n",
        "            revise_rating_pred.append(rating_true[i])\n",
        "        else:\n",
        "            revise_rating_pred.append(rating_pred[i])\n",
        "\n",
        "    rating_pred = revise_rating_pred\n",
        "\n",
        "    tag_true = []\n",
        "\n",
        "    for index_list in tags_true:\n",
        "        result_true = [0] * 10  # Create a list of length num_classes.\n",
        "        for index in index_list:\n",
        "            result_true[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "        tag_true.append(result_true)\n",
        "\n",
        "    tag_true = np.array(tag_true)\n",
        "    tags_pred_proba = np.array(tags_pred_proba)\n",
        "\n",
        "    thr = 0\n",
        "    max_f1_score = 0\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        tag_pred = []\n",
        "        for index_list in tags_pred[threshold]:\n",
        "            result_pred = [0] * 10 # Create a list of length num_classes.\n",
        "            for index in index_list:\n",
        "                result_pred[index] = 1  # Fill the corresponding index with 1.\n",
        "\n",
        "            tag_pred.append(result_pred)\n",
        "\n",
        "        f1 = f1_score(tag_true, tag_pred, average='macro', zero_division=0)\n",
        "        if max_f1_score < f1:\n",
        "            thr = threshold\n",
        "            max_f1_score = f1\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "\n",
        "    # Plot ROC curve for each classifier\n",
        "    plt.figure()\n",
        "    for num_classes in range(10):\n",
        "        tt, tp = tag_true[:, num_classes], tags_pred_proba[:, num_classes]\n",
        "\n",
        "        score = roc_auc_score(tt, tp)\n",
        "        tag = tag_label_encoder.classes_[num_classes]\n",
        "        print(f\"{tag} : {score}\")\n",
        "        fpr[num_classes], tpr[num_classes], _ = roc_curve(tt, tp)\n",
        "        plt.plot(fpr[num_classes], tpr[num_classes], label=f'{tag}(area={score:.2f})')\n",
        "    print()\n",
        "\n",
        "    print(\"tag_roc_auc_score : \", roc_auc_score(tag_true, tags_pred_proba))\n",
        "    print(\"f1_score : \", max_f1_score)\n",
        "    print(\"threshold : \", thr)\n",
        "\n",
        "    rating_acc = accuracy_score(rating_true, rating_pred)\n",
        "    print(f\"rating_acc : {rating_acc}\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Tag Prediction')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9txbqiWeK6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LEDoyOhuK6XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xjYo0oVKK6VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSQXQuaCK6TX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
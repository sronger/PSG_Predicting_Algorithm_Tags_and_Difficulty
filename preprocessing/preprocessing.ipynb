{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "700edcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_limit</th>\n",
       "      <th>memory_limit</th>\n",
       "      <th>input_file</th>\n",
       "      <th>output_file</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846/F</th>\n",
       "      <td>1 second</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>This is an interactive task.Rudolph is a scien...</td>\n",
       "      <td>['constructive algorithms', 'implementation', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847/D</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>Josuke is tired of his peaceful life in Morioh...</td>\n",
       "      <td>['data structures', 'dsu', 'greedy', 'implemen...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/E2</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>This is the hard version of the problem. The o...</td>\n",
       "      <td>['binary search', 'brute force', 'data structu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/E1</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>This is a simple version of the problem. The o...</td>\n",
       "      <td>['brute force', 'implementation', 'math']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/C</th>\n",
       "      <td>1 second</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>Rudolf has registered for a programming compet...</td>\n",
       "      <td>['constructive algorithms', 'greedy', 'impleme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_limit   memory_limit input_file output_file  \\\n",
       "1846/F    1 second  256 megabytes  standard    standard    \n",
       "1847/D   2 seconds  256 megabytes  standard    standard    \n",
       "1846/E2  2 seconds  256 megabytes  standard    standard    \n",
       "1846/E1  2 seconds  256 megabytes  standard    standard    \n",
       "1846/C    1 second  256 megabytes  standard    standard    \n",
       "\n",
       "                                               description  \\\n",
       "1846/F   This is an interactive task.Rudolph is a scien...   \n",
       "1847/D   Josuke is tired of his peaceful life in Morioh...   \n",
       "1846/E2  This is the hard version of the problem. The o...   \n",
       "1846/E1  This is a simple version of the problem. The o...   \n",
       "1846/C   Rudolf has registered for a programming compet...   \n",
       "\n",
       "                                                      tags  points  rating  \n",
       "1846/F   ['constructive algorithms', 'implementation', ...     NaN     NaN  \n",
       "1847/D   ['data structures', 'dsu', 'greedy', 'implemen...  2000.0     NaN  \n",
       "1846/E2  ['binary search', 'brute force', 'data structu...     NaN     NaN  \n",
       "1846/E1          ['brute force', 'implementation', 'math']     NaN     NaN  \n",
       "1846/C   ['constructive algorithms', 'greedy', 'impleme...     NaN     NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./codeforce_raw_data.csv', index_col=0, encoding='utf8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc2842d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80e02f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\juntae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\juntae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e403cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an interactive task.Rudolph is a scientist who studies alien life forms.\n",
    "# -> This is an interactive task. Rudolph is a scientist who studies alien life forms.\n",
    "def processing_dot_capitalize(sentences):\n",
    "    new_sentences = \"\" \n",
    "    prev = sentences[0]\n",
    "    for t in sentences:\n",
    "        if prev == '.' and t.isupper():\n",
    "            new_sentences += ' '\n",
    "        new_sentences += t\n",
    "        prev = t\n",
    "    return new_sentences\n",
    "\n",
    "# ( $$$ 1 \\\\le t_{i, j} \\\\le 10^6 $$$ )\n",
    "# -> ( $$$ 1 \\\\le t_{i, j} \\\\le 1000000 $$$ )\n",
    "def replace_exponent_notation(text):\n",
    "    # Function to replace exponent notation with numbers\n",
    "    def replace_exponent(match):\n",
    "        exponent = int(match.group(1))\n",
    "        return str(10 ** exponent)\n",
    "\n",
    "    # Replace \"10^4\" or \"10^5\" with the corresponding numbers\n",
    "    replaced_text = re.sub(r'10\\^(\\d+)', replace_exponent, text)\n",
    "\n",
    "    return replaced_text\n",
    "\n",
    "# there is a room in front of rudolph with $$$n$$$ different objects scattered around.\n",
    "# -> There is a room in front of Rudolph with $$$ n $$$ different objects scattered around.\n",
    "def add_spacing_between_dollar_signs(text):\n",
    "    # Regular expression pattern to add spacing between \"$$$\"\n",
    "    pattern = r'(?<=\\$\\$\\$)(?=\\S)|(?<=\\S)(?=\\$\\$\\$)'\n",
    "\n",
    "    # Add spacing between \"$$$\"\n",
    "    spaced_text = re.sub(pattern, ' ', text)\n",
    "\n",
    "    return spaced_text\n",
    "\n",
    "# This is an interactive task. \n",
    "# -> this is an interactive task.\n",
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def is_number(string):\n",
    "    return string.isdigit()\n",
    "\n",
    "# 2 \\\\cdot 100000 \n",
    "# -> 200000\n",
    "def calculate_multiplication(text):\n",
    "    t = text.split()  # Split the input text into a list of words\n",
    "    new_text = []  # Initialize a new list for the modified text\n",
    "    count = 0  # Initialize a count to keep track of processed elements\n",
    "    \n",
    "    # Iterate through the words in the input text\n",
    "    for i in range(len(t)):\n",
    "        if count > 0:\n",
    "            count -= 1\n",
    "            continue\n",
    "        \n",
    "        # Check if the current word and the word after it form a multiplication expression\n",
    "        if not len(t) - i < 3 and is_number(t[i]) and is_number(t[i + 2]) and t[i + 1] == '\\cdot':\n",
    "            # Evaluate and append the result of the multiplication to the new text\n",
    "            new_text.append(str(eval(t[i] + '*' + t[i + 2])))\n",
    "            count = 2  # Skip the next two words as they have been processed in the multiplication\n",
    "        else:\n",
    "            new_text.append(t[i])  # Append the current word to the new text\n",
    "    \n",
    "    return ' '.join(new_text)  # Join the modified words to form the final text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cfa93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    #text = remove_less_than_three_letters(text)\n",
    "    text = processing_dot_capitalize(text) # Run before \"lowercase\"\n",
    "    text = convert_to_lowercase(text)\n",
    "    text = add_spacing_between_dollar_signs(text)\n",
    "    text = replace_exponent_notation(text)\n",
    "    text = calculate_multiplication(text) # optional\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e8d2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(sentences):\n",
    "    return sent_tokenize(sentences)\n",
    "\n",
    "def split_words(sentence):\n",
    "    return word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f198a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(tokens):\n",
    "    # Initialize the WordNet Lemmatizer\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatize each word in the list of tokens as verbs ('v' indicates verb lemmatization)\n",
    "    tokens = [lmtzr.lemmatize(word, 'v') for word in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_words = []  # Initialize a list to store filtered words\n",
    "    stopwords = nltk.corpus.stopwords.words('english')  # Get the list of English stopwords\n",
    "    stopwords = [item for item in stopwords if len(item) > 1]  # Filter out single-letter stopwords\n",
    "    \n",
    "    for word in tokens:\n",
    "        # If the individual word is not in the stopwords list, add it to the filtered_words list\n",
    "        if word not in stopwords:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    return filtered_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c3c2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing_sentence(tokens):\n",
    "    filtered_words = remove_stopwords(tokens)\n",
    "    filtered_words = lemmatization(filtered_words)\n",
    "    return ' '.join(filtered_words).replace('$ $ $', '$$$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f861fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_sentence(sentences):\n",
    "    new_sentences = []\n",
    "\n",
    "    sentences = preprocessing(sentences)\n",
    "    sentences_list = split_sentences(sentences)\n",
    "    \n",
    "    for sentence in sentences_list:\n",
    "        tokens = split_words(sentence)\n",
    "        preprocessed_sentence = get_preprocessing_sentence(tokens)\n",
    "        if preprocessed_sentence[-1] == '.':\n",
    "            preprocessed_sentence = preprocessed_sentence[:-2]\n",
    "        new_sentences.append(preprocessed_sentence.replace(' , ', ' '))\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aca027aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e99c56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7968/7968 [01:37<00:00, 81.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "new_description = []\n",
    "for description in tqdm(df['description'].values):\n",
    "    new_description.append(get_preprocessed_sentence(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed21f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = new_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e7cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].apply(list_to_string)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c12666bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dollar_processing(arr):\n",
    "    # Initialize a new array\n",
    "    new_arr = []\n",
    "\n",
    "    # Replace consecutive '$' with '$$$'\n",
    "    i = 0\n",
    "    while i < len(arr):\n",
    "        if i + 2 < len(arr) and arr[i] == '$' and arr[i + 1] == '$' and arr[i + 2] == '$':\n",
    "            new_arr.append('$$$')\n",
    "            i += 3  # Process three '$' and increase the index by 3\n",
    "        else:\n",
    "            new_arr.append(arr[i])\n",
    "            i += 1\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f0699c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "def tokenizing_sentences(sentences):\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = get_tokenizer(\"spacy\")\n",
    "\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenizer(sentence)\n",
    "        new_sentences.append(dollar_processing(tokens))\n",
    "        \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9da8fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a list to a string\n",
    "def list_to_string(lst):\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b615307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juntae\\anaconda3\\envs\\falcon\\lib\\site-packages\\cupy\\_environment.py:216: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n",
      "C:\\Users\\juntae\\anaconda3\\envs\\falcon\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df['description'] = tokenizing_sentences(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09e4ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_limit</th>\n",
       "      <th>memory_limit</th>\n",
       "      <th>input_file</th>\n",
       "      <th>output_file</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846/F</th>\n",
       "      <td>1 second</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>interactive task rudolph a scientist study ali...</td>\n",
       "      <td>['constructive algorithms', 'implementation', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847/D</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>josuke tire peaceful life morioh follow nephew...</td>\n",
       "      <td>['data structures', 'dsu', 'greedy', 'implemen...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/E2</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>hard version problem difference version $$$ n ...</td>\n",
       "      <td>['binary search', 'brute force', 'data structu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/E1</th>\n",
       "      <td>2 seconds</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>a simple version problem difference version $$...</td>\n",
       "      <td>['brute force', 'implementation', 'math']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846/C</th>\n",
       "      <td>1 second</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>standard</td>\n",
       "      <td>standard</td>\n",
       "      <td>rudolf register a program competition follow r...</td>\n",
       "      <td>['constructive algorithms', 'greedy', 'impleme...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_limit   memory_limit input_file output_file  \\\n",
       "1846/F    1 second  256 megabytes  standard    standard    \n",
       "1847/D   2 seconds  256 megabytes  standard    standard    \n",
       "1846/E2  2 seconds  256 megabytes  standard    standard    \n",
       "1846/E1  2 seconds  256 megabytes  standard    standard    \n",
       "1846/C    1 second  256 megabytes  standard    standard    \n",
       "\n",
       "                                               description  \\\n",
       "1846/F   interactive task rudolph a scientist study ali...   \n",
       "1847/D   josuke tire peaceful life morioh follow nephew...   \n",
       "1846/E2  hard version problem difference version $$$ n ...   \n",
       "1846/E1  a simple version problem difference version $$...   \n",
       "1846/C   rudolf register a program competition follow r...   \n",
       "\n",
       "                                                      tags  points  rating  \n",
       "1846/F   ['constructive algorithms', 'implementation', ...     NaN     NaN  \n",
       "1847/D   ['data structures', 'dsu', 'greedy', 'implemen...  2000.0     NaN  \n",
       "1846/E2  ['binary search', 'brute force', 'data structu...     NaN     NaN  \n",
       "1846/E1          ['brute force', 'implementation', 'math']     NaN     NaN  \n",
       "1846/C   ['constructive algorithms', 'greedy', 'impleme...     NaN     NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'] = df['description'].apply(list_to_string)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b1f35b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('codeforce_processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab02e182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
